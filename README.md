# Results: Learning Cortical Representations through perturbed and adversarial dreaming
This project is based on the article "Learning Cortical Representations through perturbed and adversarial dreaming," which explores the role of dreams in the formation of meaningful knowledge in the brain.

## Article Summary

The main goal of the article discussed in this project is to propose a new functional model of cortical representation learning that suggests dreams, and in particular their creative combination of episodic memories, play an essential role in forming semantic representations over the course of development. The authors introduce a cortical architecture inspired by generative adversarial networks (GANs) and train the model on standard datasets of natural images to evaluate the quality of the learned representations. The research aims to provide insight into how sensory experience is processed and represented in the brain, with potential implications for understanding how humans and other animals learn from sensory experience.

Link to the original article: [Learning cortical representations](https://elifesciences.org/articles/76384)


## Datasets

The datasets used in this project are publicly available and are named:
- CIFAR10: [Download Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)
- SVHN: [Download Dataset](http://ufldl.stanford.edu/housenumbers/)
- MNIST: [Download Dataset](https://www.tensorflow.org/datasets/catalog/mnist?hl=it)
- Fashion-MNIST: [Download Dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist)

## Repository Contents

- The Overleaf Report: The report discussing the article in Overleaf format can be found inside the github repository.

- The `codes` Folder: This folder contains the following codes in both Jupyter Notebook and Python formats:

  1. `model`: This code implements the model used in the project.
  2. `functions`: This code includes various functions used for data processing and analysis.
  3. `training`: This code provides the training process for the model.
  4. `samples`: This code generates sample images.
  5. `evaluating`: This code evaluates the model's performance.
  6. `evaluating_occlusions`: This code evaluates the model's performance with occlusions.

## Results and Resources

The results of the project, including sample images and trained models, are large files that can be accessed through the following Google Drive link: [Results and Resources](https://drive.google.com/drive/folders/1ICiG1oI5mtNa3IMUPqH2Jn6dpg38qHH3).


