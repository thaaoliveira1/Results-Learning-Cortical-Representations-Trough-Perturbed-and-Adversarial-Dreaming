{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Import the torch library\n",
    "import torch.nn as nn  # Import the torch.nn module\n",
    "import torchvision.models as models  # Import the models module from torchvision\n",
    "import torch.nn.functional as F  # Import the torch.nn.functional module\n",
    "from torch.nn.functional import adaptive_avg_pool2d  # Import the adaptive_avg_pool2d function from torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu, latent_dim, ngf=64, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.latent_dim = latent_dim\n",
    "        self.bias = True\n",
    "\n",
    "        # Define the transposed convolution layers\n",
    "        self.tconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, ngf*4, kernel_size=4, stride=1, padding=0, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        # state size: (ngf*4) x 4 x 4\n",
    "\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        # state size: (ngf*2) x 8 x 8\n",
    "\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        # state size: (ngf) x 16 x 16\n",
    "\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, img_channels, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # state size: (img_channels) x 32 x 32\n",
    "\n",
    "    def forward(self, input, reverse=True):\n",
    "        fc1 = input.view(input.size(0), input.size(1), 1, 1)\n",
    "        # Reshape the input tensor\n",
    "\n",
    "        tconv1_output = self.tconv1(fc1)\n",
    "        # Apply the first transposed convolution layer\n",
    "\n",
    "        tconv2_output = self.tconv2(tconv1_output)\n",
    "        # Apply the second transposed convolution layer\n",
    "\n",
    "        tconv3_output = self.tconv3(tconv2_output)\n",
    "        # Apply the third transposed convolution layer\n",
    "\n",
    "        output = self.tconv4(tconv3_output)\n",
    "        # Apply the fourth transposed convolution layer\n",
    "\n",
    "        if reverse:\n",
    "            output = grad_reverse(output)\n",
    "            # Reverse the gradient of the output (custom function)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The `Generator` class is defined as a subclass of `nn.Module`, which is the base class for all neural network modules in PyTorch.\n",
    "\n",
    "2. In the `__init__` method, the constructor initializes the generator by specifying the number of GPUs (`ngpu`), the dimension of the input noise vector (`latent_dim`), the number of filters in the generator's convolutional layers (`ngf`), and the number of channels in the output image (`img_channels`).\n",
    "\n",
    "3. The generator uses transposed convolution layers (`nn.ConvTranspose2d`) to upsample the input noise and generate images. The transposed convolution layers are defined and initialized in the constructor.\n",
    "    - `self.tconv1` is the first transposed convolution layer that takes the input noise and produces feature maps with `ngf*4` channels. It uses a kernel size of 4, stride of 1, and no padding. It is followed by a leaky ReLU activation function (`nn.LeakyReLU`).\n",
    "    - `self.tconv2` is the second transposed convolution layer that takes the output of `self.tconv1` and produces feature maps with `ngf*2` channels. It uses a kernel size of 4, stride of 2, and padding of 1. It is also followed by a leaky ReLU activation function.\n",
    "    - `self.tconv3` is the third transposed convolution layer that takes the output of `self.tconv2` and produces feature maps with `ngf` channels. It uses the same configuration as `self.tconv2`.\n",
    "    - `self.tconv4` is the final transposed convolution layer that takes the output of `self.tconv3` and produces the final output image. It uses a kernel size of 4, stride of 2, and padding of 1. It is followed by a hyperbolic tangent (`nn.Tanh`) activation function to ensure the output values are within the range [-1, 1].\n",
    "    \n",
    "4. The `forward` method implements the forward pass of the generator. It takes an input tensor (`input`) and a boolean flag (`reverse`) to indicate whether to reverse the gradient of the output.\n",
    "    - The input tensor is reshaped (`view`) to have dimensions (batch_size, latent_dim, 1, 1), where `latent_dim` is the dimension of the input noise vector.\n",
    "    - The reshaped tensor is passed through each transposed convolution layer (`self.tconv1`, `self.tconv2`, `self.tconv3`, `self.tconv4`) sequentially.\n",
    "    - If the `reverse` flag is `True`, the gradient of the output tensor is reversed using a custom function called `grad_reverse` (not defined in the provided code). This is often used in domain adaptation tasks to fool the discriminator by making the generator's output look more like the target domain.\n",
    "    - The final output tensor is returned.\n",
    "\n",
    "Overall, this code defines the architecture of a generator model for a GAN, which generates synthetic images from random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        # The forward pass returns the input tensor as is\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        # The backward pass multiplies the gradient output by -1\n",
    "        return (grad_output * -1)\n",
    "\n",
    "def grad_reverse(x):\n",
    "    # Apply the gradient reversal operation using the custom GradReverse function\n",
    "    return GradReverse.apply(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code defines a custom autograd function called `GradientReverse`. This function will be used to reverse the gradient during the backpropagation process.\n",
    "\n",
    "2. The `forward` method of  `GradientReverse ` takes an input tensor  `x ` and returns it as is, without any modifications. This is the identity operation.\n",
    "\n",
    "3. The  `backward ` method of  `GradientReverse ` takes the gradient of the output with respect to the forward pass and multiplies it by -1. This effectively reverses the gradient direction.\n",
    "\n",
    "4. The  `grad_reverse ` function is defined to apply the gradient reversal operation. It calls the  `apply ` method of  `GradientReverse ` to perform the operation on the input tensor  `x `.\n",
    "\n",
    "By using the  `grad_reverse ` function, you can reverse the gradients during the backpropagation process, which can be useful for tasks such as domain adaptation in adversarial learning setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        # Retrieve the batch size from the input tensor\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        # Reshape the input tensor to have shape (batch_size, -1)\n",
    "        flattened_input = input.view(batch_size, -1)\n",
    "\n",
    "        # Return the flattened input tensor\n",
    "        return flattened_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code defines a custom module called  `Flatten `, which inherits from  `torch.nn.Module `. This module is responsible for flattening the input tensor.\n",
    "\n",
    "2. The  `forward ` method of  `Flatten ` is overridden to define the forward pass operation.\n",
    "\n",
    "3. Inside the  `forward ` method, the batch size is obtained from the input tensor using  `x.shape[0] `. This represents the number of samples in the batch.\n",
    "\n",
    "4. The input tensor is then reshaped using  `x.view(batch_size, -1) `. The  `view ` function is used to reshape the tensor, where  `batch_size ` represents the number of samples in the batch, and  `1 ` infers the correct size for the remaining dimensions.\n",
    "\n",
    "5. The flattened input tensor is returned as the output of the forward pass.\n",
    "\n",
    "The purpose of the  `Flatten ` module is to flatten multi-dimensional input tensors into a 2D representation, which is commonly required when transitioning from convolutional layers to fully connected layers in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, latent_dim, ndf=64, img_channels=3, dropout_prob=0.0):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.ndf = ndf\n",
    "        self.bias = True\n",
    "\n",
    "        # Input size: (img_channels) x 32 x 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, ndf, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output size: (ndf) x 16 x 16\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output size: (ndf*2) x 8 x 8\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output size: (latent_dim) x 4 x 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 4, latent_dim, kernel_size=4, stride=2, padding=0, bias=self.bias),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        # Output size: 1 x 1\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 4, 1, kernel_size=4, stride=2, padding=0, bias=self.bias),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        # Sigmoid activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Pass input through the convolutional layers\n",
    "        conv1 = self.conv1(input)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "\n",
    "        # Perform the real/fake classification\n",
    "        fc_dis = self.sigmoid(self.dis(conv3))\n",
    "\n",
    "        # Extract the encoded feature representation\n",
    "        fc_enc = self.conv4(conv3)\n",
    "\n",
    "        # Reshape the real/fake classification tensor\n",
    "        realfake = fc_dis.view(-1, 1).squeeze(1)\n",
    "\n",
    "        return fc_enc, realfake\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code defines a discriminator model for a GAN. The discriminator takes an input image and outputs both an encoded feature representation and a real/fake classification.\n",
    "\n",
    "2. The  `Discriminator ` class inherits from  `nn.Module ` and defines the discriminator architecture.\n",
    "\n",
    "3. The constructor ( `__init__ ` method) initializes the discriminator by specifying the number of GPUs ( `ngpu `), the dimension of the encoded feature representation ( `latent_dim `), the number of filters in the discriminator's convolutional layers ( `ndf `), the number of channels in the input image ( `img_channels `), and the dropout probability ( `dropout_prob `).\n",
    "\n",
    "4. The discriminator uses convolutional layers ( `nn.Conv2d `) followed by leaky ReLU activation functions ( `nn.LeakyReLU `) to process the input image and extract features.\n",
    "\n",
    "5. The discriminator has four convolutional layers ( `self.conv1 `,  `self.conv2 `,  `self.conv3 `,  `self.conv4 `) that progressively downsample the input image.\n",
    "\n",
    "6. The  `self.dis ` layer performs a convolution followed by flattening to output the real/fake classification.\n",
    "\n",
    "7. The  `self.conv4 ` layer performs a convolution followed by flattening to output the encoded feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32, num_classes=10):\n",
    "        super(OutputClassifier, self).__init__()\n",
    "\n",
    "        # Define the fully connected layer for classification\n",
    "        self.fc_classifier = nn.Sequential(\n",
    "            nn.Linear(input_size, num_classes, bias=True),\n",
    "        )\n",
    "\n",
    "        # Softmax activation function for class probabilities\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Perform classification using the fully connected layer\n",
    "        classes = self.fc_classifier(input)\n",
    "\n",
    "        return classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code defines an output classifier model that takes an input and predicts the class labels.\n",
    "\n",
    "2. The  `OutputClassifier ` class inherits from  `nn.Module ` and defines the classifier architecture.\n",
    "\n",
    "3. The constructor ( `__init__ ` method) initializes the classifier by specifying the input size ( `input_size `), the size of the hidden layer ( `hidden_size `), and the number of classes ( `num_classes `).\n",
    "\n",
    "4. The classifier consists of a single fully connected layer ( `nn.Linear `) that maps the input to the number of classes. This layer performs the classification task.\n",
    "\n",
    "5. The  `self.softmax ` layer applies the softmax activation function to the output of the classifier. This converts the output logits into class probabilities.\n",
    "\n",
    "6. The forward pass is implemented in the  `forward ` method. It takes an input, performs classification using the fully connected layer, and returns the predicted classes.\n",
    "\n",
    "Please note that the  `softmax ` function is typically not applied within the model, as it is usually incorporated in the loss function or evaluation metric outside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=10):\n",
    "        super(InputClassifier, self).__init__()\n",
    "\n",
    "        # Define the fully connected layer for classification\n",
    "        self.fc_classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_classes, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Reshape the input from batch_size x 28 x 28 to batch_size x (28*28)\n",
    "        out = input.view(input.size(0), -1)\n",
    "\n",
    "        # Perform classification using the fully connected layer\n",
    "        out = self.fc_classifier(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code defines an input classifier model that takes an input and predicts the class labels.\n",
    "\n",
    "2. The  `InputClassifier ` class inherits from  `nn.Module ` and defines the classifier architecture.\n",
    "\n",
    "3. The constructor ( `__init__ ` method) initializes the classifier by specifying the input dimension ( `input_dim `) and the number of classes ( `num_classes `).\n",
    "\n",
    "4. The classifier consists of a single fully connected layer ( `nn.Linear `) that maps the input to the number of classes. This layer performs the classification task.\n",
    "\n",
    "5. The forward pass is implemented in the  `forward ` method. It takes an input and reshapes it from batch_size x 28 x 28 to batch_size x (28*28). This flattens the input image into a 1D vector.\n",
    "\n",
    "6. The flattened input is then passed through the fully connected layer ( `self.fc_classifier `), which applies the linear transformation (input * A + b) where A and b are learnable parameters of the linear layer.\n",
    "\n",
    "7. The output  `out ` represents the logits or scores for each class. The final predicted class can be obtained by applying a softmax activation function or using an appropriate loss function during training.\n",
    "\n",
    "Please note that the code assumes the input shape to be batch_size x 28 x 28, which is a common representation for images in MNIST-like datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    DEFAULT_BLOCK_INDEX = 3  # Index of default block of inception to return\n",
    "\n",
    "    # Maps feature dimensionality to their output block indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling features\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self, output_blocks=[DEFAULT_BLOCK_INDEX], resize_input=True, normalize_input=True, requires_grad=False):\n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, 'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        # Load the pretrained InceptionV3 model\n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        # Set the requires_grad property of parameters\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Get Inception feature maps\"\"\"\n",
    "        output = []\n",
    "        x = input\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                output.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a PyTorch module called `InceptionV3`, which represents a pretrained InceptionV3 network returning feature maps.\n",
    "\n",
    "The key components and functionalities of the code are as follows:\n",
    "\n",
    "1. The class variable `DEFAULT_BLOCK_INDEX` is set to 3, representing the index of the default block of the Inception network to return.\n",
    "\n",
    "2. The dictionary `BLOCK_INDEX_BY_DIM` maps feature dimensionality to their respective output block indices.\n",
    "\n",
    "3. The `__init__` method initializes the `InceptionV3` module. It takes several parameters:\n",
    "   - `output_blocks`: A list of output block indices to return. The default is the `DEFAULT_BLOCK_INDEX` (3).\n",
    "   - `resize_input`: A boolean indicating whether to resize the input. The default is `True`.\n",
    "   - `normalize_input`: A boolean indicating whether to normalize the input. The default is `True`.\n",
    "   - `requires_grad`: A boolean indicating whether the model's parameters require gradient computation. The default is `False`.\n",
    "\n",
    "4. The method loads the pretrained InceptionV3 model using `models.inception_v3(pretrained=True)`.\n",
    "\n",
    "5. The different blocks of the InceptionV3 model are constructed and stored in `self.blocks` using `nn.Sequential`.\n",
    "   - Block 0 corresponds to the input to maxpool1 and consists of several convolutional layers and a max pooling layer.\n",
    "   - Block 1 corresponds to maxpool1 to maxpool2 and consists of convolutional layers and a max pooling layer.\n",
    "   - Block 2 corresponds to maxpool2 to the auxiliary classifier and consists of several mixed layers.\n",
    "   - Block 3 corresponds to the auxiliary classifier to the final average pooling layer.\n",
    "   \n",
    "6. The `forward` method performs the forward pass of the InceptionV3 network. It takes an input tensor `input` and returns a list of feature maps corresponding to the selected output blocks.\n",
    "   - The input tensor is resized and normalized if specified.\n",
    "   - The input tensor is passed through the blocks sequentially, and the output feature maps are stored in the `output` list.\n",
    "   - The method breaks the loop when it reaches the last needed block.\n",
    "\n",
    "Overall, this code allows you to use the pretrained InceptionV3 model to extract specific feature maps based on the desired output blocks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
