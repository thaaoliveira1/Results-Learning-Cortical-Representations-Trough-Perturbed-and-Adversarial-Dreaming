{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function  # Ensures print function compatibility with Python 2.x\n",
    "import argparse  # Library for parsing command-line arguments\n",
    "import os  # Library for interacting with the operating system\n",
    "import copy  # Library for creating object copies\n",
    "import numpy as np  # Numerical computing library\n",
    "import random  # Library for generating random numbers\n",
    "\n",
    "import torch  # Core library for PyTorch\n",
    "import torch.nn as nn  # Library for defining neural network components\n",
    "import torch.nn.parallel  # Library for parallelizing operations on multiple GPUs\n",
    "import torch.backends.cudnn as cudnn  # Interface to the cuDNN library for GPU optimizations\n",
    "import torch.optim as optim  # Library for optimization algorithms\n",
    "import torch.utils.data  # Tools for working with datasets in PyTorch\n",
    "import torchvision.datasets as dset  # Datasets provided by torchvision\n",
    "import torchvision.transforms as transforms  # Transformations for image preprocessing\n",
    "import torchvision.utils as vutils  # Utility functions for visualizing images\n",
    "from torch.autograd import Variable  # Provides automatic differentiation for tensors\n",
    "import torch.nn.functional as F  # Library for various activation functions and loss functions\n",
    "\n",
    "from functions import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(imageSize=32, dataset='svhn', dataroot='./datasets/', num_workers=2, is_continue=1, batch_size=64, image_size=32, latent_size=256, num_epochs=55, weight_cycle_consistency=1.0, W=1.0, N=1.0, R=1.0, epsilon=0.0, num_filters=64, dropout_prob=0.0, learning_rate_generator=0.0002, learning_rate_discriminator=0.0002, beta1=0.5, lmbd=0.5, num_gpus=1, output_folder='output', gpu_id='0', outf='output', niter=55)\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import argparse\n",
    "\n",
    "# Creating an argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Adding arguments with their default values and descriptions\n",
    "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to network')\n",
    "parser.add_argument('--dataset', default='svhn', help='Dataset to use: cifar10 | svnh | mnist')\n",
    "parser.add_argument('--dataroot', default='./datasets/', help='Path to the dataset')\n",
    "parser.add_argument('--num_workers', type=int, help='Number of data loading workers', default=2)\n",
    "parser.add_argument('--is_continue', type=int, default=1, help='Use pre-trained model')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Input batch size')\n",
    "parser.add_argument('--image_size', type=int, default=32, help='Height/width of the input image to the network')\n",
    "parser.add_argument('--latent_size', type=int, default=256, help='Size of the latent vector')\n",
    "parser.add_argument('--num_epochs', type=int, default=55, help='Number of epochs to train for')\n",
    "parser.add_argument('--weight_cycle_consistency', type=float, default=1.0, help='Weight of Cycle Consistency')\n",
    "parser.add_argument('--W', type=float, default=1.0, help='Wake')\n",
    "parser.add_argument('--N', type=float, default=1.0, help='NREM')\n",
    "parser.add_argument('--R', type=float, default=1.0, help='REM')\n",
    "parser.add_argument('--epsilon', type=float, default=0.0, help='Amount of noise in the wake latent space')\n",
    "parser.add_argument('--num_filters', type=int, default=64, help='Filters factor')\n",
    "parser.add_argument('--dropout_prob', type=float, default=0.0, help='Probability of dropout')\n",
    "parser.add_argument('--learning_rate_generator', type=float, default=0.0002, help='Learning rate for the generator')\n",
    "parser.add_argument('--learning_rate_discriminator', type=float, default=0.0002, help='Learning rate for the discriminator')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='Beta1 for Adam optimizer')\n",
    "parser.add_argument('--lmbd', type=float, default=0.5, help='convex combination factor for REM')\n",
    "parser.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use')\n",
    "parser.add_argument('--output_folder', default='output', help='Folder to output images and model checkpoints')\n",
    "parser.add_argument('--gpu_id', type=str, default='0', help='The ID of the specified GPU')\n",
    "parser.add_argument('--outf', default='output', help='folder to output images and model checkpoints')\n",
    "\n",
    "\n",
    "\n",
    "# Parsing the command-line arguments\n",
    "opt, unknown = parser.parse_known_args()\n",
    "\n",
    "# Set the number of iterations to the number of epochs\n",
    "opt.niter = opt.num_epochs\n",
    "\n",
    "# Assign the value of latent_size based on opt.latent_size\n",
    "latent_size = opt.latent_size\n",
    "\n",
    "# Printing the parsed arguments\n",
    "print(opt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. The code begins by importing the necessary library, **`argparse`**, which provides a way to parse command-line arguments.\n",
    "\n",
    "2. An argument parser object is created using **`argparse.ArgumentParser()`**. This object will handle the parsing of command-line arguments.\n",
    "\n",
    "3. Various arguments are added to the parser using the **`add_argument()`** method. Each argument has a unique name, a default value, and a description.\n",
    "\n",
    "4. The command-line arguments are parsed using **`parser.parse_known_args()`**, which returns two values: **`opt`** (containing the parsed argument values) and **`unknown`** (containing any unrecognized arguments).\n",
    "\n",
    "5. The parsed argument values are stored in the **`opt`** object.\n",
    "\n",
    "6. Finally, the values of the parsed arguments are printed using **`print(opt)`**.\n",
    "\n",
    "This code allows you to run the program with different options and values from the command line. Each option represents a specific setting or parameter that can be customized. The **`argparse`** library handles the parsing of these options, and the **`opt`** object stores the values for further use within the program. Printing the **`opt`** object provides a summary of the parsed argument values, allowing you to verify the settings before running the main logic of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU ID if using only 1 GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
    "\n",
    "# where to save samples and training curves\n",
    "dir_files = './results/'+opt.dataset+'/'+opt.outf\n",
    "# where to save model\n",
    "dir_checkpoint = './checkpoints/'+opt.dataset+'/'+opt.outf\n",
    "\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "try:\n",
    "    os.makedirs(dir_files)\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(dir_checkpoint)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Set the device to CUDA if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the dataset and get relevant information\n",
    "dataset, unorm, img_channels = get_dataset(opt.dataset, opt.dataroot, opt.imageSize)\n",
    "\n",
    "# Create a data loader for loading the dataset in batches\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "                                         num_workers=int(opt.num_workers), drop_last=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code sets the environment variable **`CUDA_VISIBLE_DEVICES`** to the GPU ID specified in **`opt.gpu_id`**. This ensures that only the specified GPU is used when running the program.\n",
    "\n",
    "2. The code defines two directory paths: **`dir_files`** for saving samples and training curves, and **`dir_checkpoint`** for saving models.\n",
    "\n",
    "3. The code attempts to create the directories specified by **`dir_files`** and **`dir_checkpoint`**. If the directories already exist, the **`OSError`** exception is caught and passed.\n",
    "\n",
    "4. The code checks if CUDA is available and assigns the device accordingly. If CUDA is available, the device is set to the GPU with ID 0; otherwise, it is set to CPU.\n",
    "\n",
    "5. The code calls the **`get_dataset()`** function to load the dataset specified in **`opt.dataset`** from the directory **`opt.dataroot`**, and also obtains the **`unorm`** (normalization) and **`img_channels`** (number of image channels) values.\n",
    "\n",
    "6. Finally, the code creates a **`DataLoader`** object called **`dataloader`**, which allows iterating over the dataset in batches. The batch size is specified by **`opt.batchSize`**, and the data is shuffled and loaded in parallel using **`opt.num_workers`** worker processes. The **`drop_last`** option ensures that the last incomplete batch is dropped if its size is less than **`opt.batchSize`**.\n",
    "\n",
    "This code prepares the necessary setup before training the neural network, such as configuring the device, setting up directories for saving results, and loading the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): Flatten()\n",
       "  )\n",
       "  (dis): Sequential(\n",
       "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): Flatten()\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and assign values to hyperparameters\n",
    "num_gpus = int(opt.num_gpus)\n",
    "latent_dim = int(opt.latent_size)\n",
    "batch_size = opt.batch_size\n",
    "\n",
    "# Instantiate generator and discriminator networks\n",
    "generator = Generator(num_gpus, latent_dim=latent_dim, ngf=opt.num_filters, img_channels=img_channels)\n",
    "generator.apply(initialize_weights)\n",
    "discriminator = Discriminator(num_gpus, latent_dim=latent_dim, ndf=opt.num_filters, img_channels=img_channels, dropout_prob=opt.dropout_prob)\n",
    "discriminator.apply(initialize_weights)\n",
    "\n",
    "\n",
    "# Move networks to the GPU\n",
    "generator.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code sets up some hyperparameters, such as the number of GPUs available (num_gpus), the size of the latent space (latent_dim), and the batch size (batch_size).\n",
    "\n",
    "2. Two neural network models are instantiated: the generator (named \"generator\") and the discriminator (named \"discriminator\").\n",
    "\n",
    "3. The generator is an instance of the Generator class, which takes the number of GPUs, latent dimension, number of filters, and number of channels as arguments.\n",
    "\n",
    "4. The discriminator is an instance of the Discriminator class, which takes similar arguments as the generator along with a dropout probability.\n",
    "\n",
    "5. Weight initialization is applied to both the generator and discriminator using the weights_init function.\n",
    "\n",
    "6. The generator and discriminator models are moved to the specified device (e.g., GPU) using the to() method.\n",
    "\n",
    "7. This ensures that the computations for these models will be performed on the GPU if available, which can significantly speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizers for discriminator and generator\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=opt.learning_rate_discriminator, betas=(opt.beta1, 0.999))\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=opt.learning_rate_generator, betas=(opt.beta1, 0.999))\n",
    "\n",
    "# Initialize lists to store losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "r_losses_real = []\n",
    "r_losses_fake = []\n",
    "kl_losses = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sets up optimizers for the discriminator and generator models.\n",
    "\n",
    "1. The discriminator_optimizer uses the Adam optimizer and takes the discriminator parameters, learning rate (lrD), and beta values as arguments.\n",
    "\n",
    "2. The generator_optimizer uses the Adam optimizer and takes the generator parameters, learning rate (lrG), and beta values as arguments.\n",
    "\n",
    "3. Lists are initialized to store various types of losses during training.\n",
    "\n",
    "4. **discriminator_losses:** Stores the losses of the discriminator model.\n",
    "\n",
    "5. **generator_losses:** Stores the losses of the generator model.\n",
    "\n",
    "6. **real_losses:** Stores losses related to real images.\n",
    "\n",
    "7. **fake_losses:** Stores losses related to fake/generated images.\n",
    "\n",
    "8. **kl_losses:** Stores Kullback-Leibler divergence losses, which are often used in variational autoencoders (VAEs) or other generative models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model detected, restart training...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(dir_checkpoint+'/trained.pth') and opt.is_continue:\n",
    "    # Load data from last checkpoint\n",
    "    print('Loading pre-trained model...')\n",
    "    checkpoint = torch.load(dir_checkpoint+'/trained.pth', map_location=torch.device('cpu'))\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    generator_optimizer.load_state_dict(checkpoint['g_optim'])\n",
    "    discriminator_optimizer.load_state_dict(checkpoint['d_optim'])\n",
    "    d_losses = checkpoint.get('d_losses', [float('inf')])\n",
    "    g_losses = checkpoint.get('g_losses', [float('inf')])\n",
    "    r_losses_real = checkpoint.get('r_losses_real', [float('inf')])\n",
    "    r_losses_fake = checkpoint.get('r_losses_fake', [float('inf')])\n",
    "    kl_losses = checkpoint.get('kl_losses', [float('inf')])\n",
    "    print('Start training from loaded model...')\n",
    "else:\n",
    "    print('No pre-trained model detected, restart training...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions\n",
    "discriminator_criterion = nn.BCELoss()  # Binary Cross Entropy Loss for the discriminator\n",
    "reconstruction_criterion = nn.MSELoss()  # Mean Squared Error Loss for reconstruction\n",
    "\n",
    "# Create tensor placeholders\n",
    "discriminator_label = torch.zeros(opt.batch_size, dtype=torch.float32, device=device)\n",
    "real_label_value = 1.0\n",
    "fake_label_value = 0\n",
    "\n",
    "evaluation_noise = torch.randn(batch_size, latent_dim, device=device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "1. The code defines two loss functions: **`discriminator_criterion`** and **`reconstruction_criterion`**. The **`BCELoss`** (Binary Cross Entropy Loss) is used for the discriminator, and the **`MSELoss`** (Mean Squared Error Loss) is used for reconstruction.\n",
    "\n",
    "2. The variables **`dis_criterion`** and **`rec_criterion`** are changed to **`discriminator_criterion`** and **`reconstruction_criterion`**, respectively. \n",
    "\n",
    "3. The variable names **`dis_label`**, **`real_label_value`**, **`fake_label_value`**, and **`eval_noise`** are changed to **`discriminator_label`**, **`real_label_value`**, **`fake_label_value`**, and **`evaluation_noise`**, respectively.\n",
    "\n",
    "4. The order and structure of the code remain unchanged as they are necessary for defining the loss functions and creating tensor placeholders.\n",
    "\n",
    "Overall, this code snippet defines the loss functions for the discriminator and reconstruction tasks. The **`BCELoss`** is commonly used for binary classification tasks, such as determining whether an image is real or fake. The **`MSELoss`** is used for measuring the pixel-wise difference between the input and reconstructed images. The tensor placeholders are created to hold the discriminator labels, real and fake label values, and noise for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/55][200/1144]  Loss_D: 1.3660  Loss_G: -0.6908  Loss_R_real: 0.1806  Loss_R_fake: 0.2333  D(x): 0.5650  D(G(z)): 0.4830  latent_norm : 11.2963  \n",
      "[0/55][400/1144]  Loss_D: 1.3653  Loss_G: -0.6911  Loss_R_real: 0.1657  Loss_R_fake: 0.2432  D(x): 0.5147  D(G(z)): 0.5073  latent_norm : 16.1570  \n",
      "[0/55][600/1144]  Loss_D: 1.3741  Loss_G: -0.6942  Loss_R_real: 0.1451  Loss_R_fake: 0.2405  D(x): 0.4905  D(G(z)): 0.5026  latent_norm : 17.3873  \n",
      "[0/55][800/1144]  Loss_D: 1.3767  Loss_G: -0.6947  Loss_R_real: 0.1286  Loss_R_fake: 0.2351  D(x): 0.5159  D(G(z)): 0.5285  latent_norm : 13.6146  \n",
      "[0/55][1000/1144]  Loss_D: 1.3773  Loss_G: -0.6949  Loss_R_real: 0.1175  Loss_R_fake: 0.2227  D(x): 0.5004  D(G(z)): 0.5010  latent_norm : 15.8456  \n",
      "Model successfully saved.\n",
      "[1/55][200/1144]  Loss_D: 1.4003  Loss_G: -0.7053  Loss_R_real: 0.0653  Loss_R_fake: 0.2099  D(x): 0.4839  D(G(z)): 0.4772  latent_norm : 14.7321  \n",
      "[1/55][400/1144]  Loss_D: 1.4019  Loss_G: -0.7048  Loss_R_real: 0.0597  Loss_R_fake: 0.2037  D(x): 0.5112  D(G(z)): 0.5043  latent_norm : 12.9308  \n",
      "[1/55][600/1144]  Loss_D: 1.4014  Loss_G: -0.7033  Loss_R_real: 0.0565  Loss_R_fake: 0.2183  D(x): 0.5053  D(G(z)): 0.5058  latent_norm : 16.6932  \n",
      "[1/55][800/1144]  Loss_D: 1.4015  Loss_G: -0.7032  Loss_R_real: 0.0542  Loss_R_fake: 0.2215  D(x): 0.5065  D(G(z)): 0.5141  latent_norm : 16.0915  \n",
      "[1/55][1000/1144]  Loss_D: 1.4010  Loss_G: -0.7026  Loss_R_real: 0.0525  Loss_R_fake: 0.2233  D(x): 0.5107  D(G(z)): 0.5122  latent_norm : 14.9876  \n",
      "Model successfully saved.\n",
      "[2/55][200/1144]  Loss_D: 1.3963  Loss_G: -0.7008  Loss_R_real: 0.0414  Loss_R_fake: 0.2077  D(x): 0.4858  D(G(z)): 0.4902  latent_norm : 14.3934  \n",
      "[2/55][400/1144]  Loss_D: 1.3956  Loss_G: -0.7007  Loss_R_real: 0.0405  Loss_R_fake: 0.2109  D(x): 0.4961  D(G(z)): 0.5065  latent_norm : 15.0168  \n",
      "[2/55][600/1144]  Loss_D: 1.3949  Loss_G: -0.7001  Loss_R_real: 0.0399  Loss_R_fake: 0.1956  D(x): 0.5035  D(G(z)): 0.4978  latent_norm : 15.8875  \n",
      "[2/55][800/1144]  Loss_D: 1.3944  Loss_G: -0.7003  Loss_R_real: 0.0396  Loss_R_fake: 0.1939  D(x): 0.5071  D(G(z)): 0.5087  latent_norm : 14.1873  \n",
      "[2/55][1000/1144]  Loss_D: 1.3942  Loss_G: -0.7003  Loss_R_real: 0.0393  Loss_R_fake: 0.1934  D(x): 0.5107  D(G(z)): 0.5144  latent_norm : 14.9925  \n",
      "Model successfully saved.\n",
      "[3/55][200/1144]  Loss_D: 1.3907  Loss_G: -0.7007  Loss_R_real: 0.0375  Loss_R_fake: 0.1653  D(x): 0.4977  D(G(z)): 0.5006  latent_norm : 15.4208  \n",
      "[3/55][400/1144]  Loss_D: 1.3906  Loss_G: -0.6996  Loss_R_real: 0.0367  Loss_R_fake: 0.1661  D(x): 0.4969  D(G(z)): 0.5020  latent_norm : 14.4751  \n",
      "[3/55][600/1144]  Loss_D: 1.3900  Loss_G: -0.7001  Loss_R_real: 0.0364  Loss_R_fake: 0.1593  D(x): 0.4983  D(G(z)): 0.5035  latent_norm : 16.0842  \n",
      "[3/55][800/1144]  Loss_D: 1.3896  Loss_G: -0.7005  Loss_R_real: 0.0362  Loss_R_fake: 0.1630  D(x): 0.4994  D(G(z)): 0.5033  latent_norm : 12.7830  \n",
      "[3/55][1000/1144]  Loss_D: 1.3892  Loss_G: -0.7004  Loss_R_real: 0.0362  Loss_R_fake: 0.1613  D(x): 0.5035  D(G(z)): 0.5010  latent_norm : 15.6196  \n",
      "Model successfully saved.\n",
      "[4/55][200/1144]  Loss_D: 1.3843  Loss_G: -0.6992  Loss_R_real: 0.0364  Loss_R_fake: 0.1574  D(x): 0.5033  D(G(z)): 0.5091  latent_norm : 14.9890  \n",
      "[4/55][400/1144]  Loss_D: 1.3840  Loss_G: -0.6984  Loss_R_real: 0.0352  Loss_R_fake: 0.1676  D(x): 0.4993  D(G(z)): 0.5091  latent_norm : 13.7487  \n",
      "[4/55][600/1144]  Loss_D: 1.3838  Loss_G: -0.6993  Loss_R_real: 0.0352  Loss_R_fake: 0.1578  D(x): 0.5101  D(G(z)): 0.5024  latent_norm : 14.9276  \n",
      "[4/55][800/1144]  Loss_D: 1.3833  Loss_G: -0.6988  Loss_R_real: 0.0350  Loss_R_fake: 0.1552  D(x): 0.4990  D(G(z)): 0.4988  latent_norm : 14.2870  \n",
      "[4/55][1000/1144]  Loss_D: 1.3827  Loss_G: -0.6985  Loss_R_real: 0.0351  Loss_R_fake: 0.1551  D(x): 0.5136  D(G(z)): 0.5034  latent_norm : 15.6401  \n",
      "Model successfully saved.\n",
      "[5/55][200/1144]  Loss_D: 1.3786  Loss_G: -0.6947  Loss_R_real: 0.0343  Loss_R_fake: 0.1693  D(x): 0.5101  D(G(z)): 0.5008  latent_norm : 14.6479  \n",
      "[5/55][400/1144]  Loss_D: 1.3797  Loss_G: -0.6948  Loss_R_real: 0.0335  Loss_R_fake: 0.1703  D(x): 0.4977  D(G(z)): 0.4971  latent_norm : 15.6645  \n",
      "[5/55][600/1144]  Loss_D: 1.3795  Loss_G: -0.6941  Loss_R_real: 0.0327  Loss_R_fake: 0.1614  D(x): 0.5049  D(G(z)): 0.4963  latent_norm : 14.0898  \n",
      "[5/55][800/1144]  Loss_D: 1.3798  Loss_G: -0.6941  Loss_R_real: 0.0325  Loss_R_fake: 0.1592  D(x): 0.5016  D(G(z)): 0.4939  latent_norm : 15.1016  \n",
      "[5/55][1000/1144]  Loss_D: 1.3800  Loss_G: -0.6941  Loss_R_real: 0.0322  Loss_R_fake: 0.1641  D(x): 0.5027  D(G(z)): 0.5043  latent_norm : 14.0431  \n",
      "Model successfully saved.\n",
      "[6/55][200/1144]  Loss_D: 1.3762  Loss_G: -0.6913  Loss_R_real: 0.0309  Loss_R_fake: 0.1611  D(x): 0.4989  D(G(z)): 0.4841  latent_norm : 16.4885  \n",
      "[6/55][400/1144]  Loss_D: 1.3754  Loss_G: -0.6912  Loss_R_real: 0.0304  Loss_R_fake: 0.1642  D(x): 0.5083  D(G(z)): 0.4980  latent_norm : 15.9068  \n",
      "[6/55][600/1144]  Loss_D: 1.3747  Loss_G: -0.6910  Loss_R_real: 0.0307  Loss_R_fake: 0.1689  D(x): 0.5021  D(G(z)): 0.5009  latent_norm : 14.0374  \n",
      "[6/55][800/1144]  Loss_D: 1.3744  Loss_G: -0.6909  Loss_R_real: 0.0309  Loss_R_fake: 0.1763  D(x): 0.5029  D(G(z)): 0.4925  latent_norm : 14.3375  \n",
      "[6/55][1000/1144]  Loss_D: 1.3737  Loss_G: -0.6908  Loss_R_real: 0.0309  Loss_R_fake: 0.1795  D(x): 0.5080  D(G(z)): 0.4997  latent_norm : 16.9315  \n",
      "Model successfully saved.\n",
      "[7/55][200/1144]  Loss_D: 1.3671  Loss_G: -0.6879  Loss_R_real: 0.0312  Loss_R_fake: 0.2051  D(x): 0.4968  D(G(z)): 0.4855  latent_norm : 13.5806  \n",
      "[7/55][400/1144]  Loss_D: 1.3661  Loss_G: -0.6868  Loss_R_real: 0.0310  Loss_R_fake: 0.1977  D(x): 0.4993  D(G(z)): 0.4839  latent_norm : 14.4243  \n",
      "[7/55][600/1144]  Loss_D: 1.3656  Loss_G: -0.6868  Loss_R_real: 0.0313  Loss_R_fake: 0.1965  D(x): 0.5284  D(G(z)): 0.5058  latent_norm : 15.2367  \n",
      "[7/55][800/1144]  Loss_D: 1.3648  Loss_G: -0.6865  Loss_R_real: 0.0314  Loss_R_fake: 0.2026  D(x): 0.5022  D(G(z)): 0.4961  latent_norm : 15.8646  \n",
      "[7/55][1000/1144]  Loss_D: 1.3638  Loss_G: -0.6859  Loss_R_real: 0.0314  Loss_R_fake: 0.2025  D(x): 0.4892  D(G(z)): 0.4821  latent_norm : 14.7288  \n",
      "Model successfully saved.\n",
      "[8/55][200/1144]  Loss_D: 1.3544  Loss_G: -0.6793  Loss_R_real: 0.0315  Loss_R_fake: 0.2130  D(x): 0.5192  D(G(z)): 0.5035  latent_norm : 14.0418  \n",
      "[8/55][400/1144]  Loss_D: 1.3533  Loss_G: -0.6791  Loss_R_real: 0.0319  Loss_R_fake: 0.2350  D(x): 0.5074  D(G(z)): 0.4766  latent_norm : 13.6336  \n",
      "[8/55][600/1144]  Loss_D: 1.3529  Loss_G: -0.6785  Loss_R_real: 0.0314  Loss_R_fake: 0.2320  D(x): 0.5335  D(G(z)): 0.4804  latent_norm : 14.8124  \n",
      "[8/55][800/1144]  Loss_D: 1.3520  Loss_G: -0.6777  Loss_R_real: 0.0313  Loss_R_fake: 0.2382  D(x): 0.5152  D(G(z)): 0.4995  latent_norm : 15.3519  \n",
      "[8/55][1000/1144]  Loss_D: 1.3510  Loss_G: -0.6771  Loss_R_real: 0.0314  Loss_R_fake: 0.2376  D(x): 0.5199  D(G(z)): 0.4737  latent_norm : 15.9126  \n",
      "Model successfully saved.\n",
      "[9/55][200/1144]  Loss_D: 1.3410  Loss_G: -0.6695  Loss_R_real: 0.0310  Loss_R_fake: 0.2457  D(x): 0.5013  D(G(z)): 0.4655  latent_norm : 14.8220  \n",
      "[9/55][400/1144]  Loss_D: 1.3412  Loss_G: -0.6702  Loss_R_real: 0.0308  Loss_R_fake: 0.2585  D(x): 0.5094  D(G(z)): 0.4871  latent_norm : 15.2706  \n",
      "[9/55][600/1144]  Loss_D: 1.3404  Loss_G: -0.6698  Loss_R_real: 0.0311  Loss_R_fake: 0.2527  D(x): 0.5303  D(G(z)): 0.5004  latent_norm : 15.5391  \n",
      "[9/55][800/1144]  Loss_D: 1.3403  Loss_G: -0.6696  Loss_R_real: 0.0310  Loss_R_fake: 0.2489  D(x): 0.5068  D(G(z)): 0.4679  latent_norm : 13.8420  \n",
      "[9/55][1000/1144]  Loss_D: 1.3400  Loss_G: -0.6693  Loss_R_real: 0.0308  Loss_R_fake: 0.2481  D(x): 0.5025  D(G(z)): 0.4947  latent_norm : 14.7445  \n",
      "Model successfully saved.\n",
      "[10/55][200/1144]  Loss_D: 1.3326  Loss_G: -0.6660  Loss_R_real: 0.0321  Loss_R_fake: 0.3104  D(x): 0.5245  D(G(z)): 0.4950  latent_norm : 15.7241  \n",
      "[10/55][400/1144]  Loss_D: 1.3324  Loss_G: -0.6655  Loss_R_real: 0.0305  Loss_R_fake: 0.3009  D(x): 0.5236  D(G(z)): 0.4818  latent_norm : 13.6079  \n",
      "[10/55][600/1144]  Loss_D: 1.3317  Loss_G: -0.6644  Loss_R_real: 0.0305  Loss_R_fake: 0.3020  D(x): 0.5162  D(G(z)): 0.4761  latent_norm : 14.5630  \n",
      "[10/55][800/1144]  Loss_D: 1.3318  Loss_G: -0.6645  Loss_R_real: 0.0306  Loss_R_fake: 0.3045  D(x): 0.5261  D(G(z)): 0.4800  latent_norm : 16.6699  \n",
      "[10/55][1000/1144]  Loss_D: 1.3308  Loss_G: -0.6641  Loss_R_real: 0.0304  Loss_R_fake: 0.3033  D(x): 0.5214  D(G(z)): 0.4671  latent_norm : 15.3072  \n",
      "Model successfully saved.\n",
      "[11/55][200/1144]  Loss_D: 1.3244  Loss_G: -0.6599  Loss_R_real: 0.0289  Loss_R_fake: 0.3205  D(x): 0.5092  D(G(z)): 0.4802  latent_norm : 13.6511  \n",
      "[11/55][400/1144]  Loss_D: 1.3230  Loss_G: -0.6588  Loss_R_real: 0.0292  Loss_R_fake: 0.3290  D(x): 0.5117  D(G(z)): 0.4785  latent_norm : 13.9746  \n",
      "[11/55][600/1144]  Loss_D: 1.3227  Loss_G: -0.6589  Loss_R_real: 0.0293  Loss_R_fake: 0.3325  D(x): 0.5381  D(G(z)): 0.4992  latent_norm : 14.8463  \n",
      "[11/55][800/1144]  Loss_D: 1.3225  Loss_G: -0.6587  Loss_R_real: 0.0295  Loss_R_fake: 0.3370  D(x): 0.5296  D(G(z)): 0.4754  latent_norm : 15.8031  \n",
      "[11/55][1000/1144]  Loss_D: 1.3208  Loss_G: -0.6575  Loss_R_real: 0.0295  Loss_R_fake: 0.3393  D(x): 0.5153  D(G(z)): 0.4772  latent_norm : 13.8939  \n",
      "Model successfully saved.\n",
      "[12/55][200/1144]  Loss_D: 1.3105  Loss_G: -0.6503  Loss_R_real: 0.0298  Loss_R_fake: 0.3725  D(x): 0.5255  D(G(z)): 0.4660  latent_norm : 15.1495  \n",
      "[12/55][400/1144]  Loss_D: 1.3117  Loss_G: -0.6515  Loss_R_real: 0.0291  Loss_R_fake: 0.3628  D(x): 0.5273  D(G(z)): 0.4598  latent_norm : 15.0095  \n",
      "[12/55][600/1144]  Loss_D: 1.3116  Loss_G: -0.6516  Loss_R_real: 0.0290  Loss_R_fake: 0.3573  D(x): 0.5287  D(G(z)): 0.4652  latent_norm : 14.6338  \n",
      "[12/55][800/1144]  Loss_D: 1.3105  Loss_G: -0.6508  Loss_R_real: 0.0291  Loss_R_fake: 0.3619  D(x): 0.4951  D(G(z)): 0.4696  latent_norm : 14.2080  \n",
      "[12/55][1000/1144]  Loss_D: 1.3109  Loss_G: -0.6512  Loss_R_real: 0.0291  Loss_R_fake: 0.3548  D(x): 0.5354  D(G(z)): 0.4659  latent_norm : 14.2277  \n",
      "Model successfully saved.\n",
      "[13/55][200/1144]  Loss_D: 1.3012  Loss_G: -0.6464  Loss_R_real: 0.0285  Loss_R_fake: 0.3304  D(x): 0.5243  D(G(z)): 0.4517  latent_norm : 14.6173  \n",
      "[13/55][400/1144]  Loss_D: 1.3002  Loss_G: -0.6454  Loss_R_real: 0.0287  Loss_R_fake: 0.3485  D(x): 0.5471  D(G(z)): 0.4908  latent_norm : 13.3864  \n",
      "[13/55][600/1144]  Loss_D: 1.2979  Loss_G: -0.6441  Loss_R_real: 0.0288  Loss_R_fake: 0.3464  D(x): 0.5612  D(G(z)): 0.4607  latent_norm : 15.1545  \n",
      "[13/55][800/1144]  Loss_D: 1.2966  Loss_G: -0.6432  Loss_R_real: 0.0286  Loss_R_fake: 0.3461  D(x): 0.5620  D(G(z)): 0.4695  latent_norm : 14.9473  \n",
      "[13/55][1000/1144]  Loss_D: 1.2960  Loss_G: -0.6426  Loss_R_real: 0.0288  Loss_R_fake: 0.3540  D(x): 0.5318  D(G(z)): 0.4680  latent_norm : 15.7747  \n",
      "Model successfully saved.\n",
      "[14/55][200/1144]  Loss_D: 1.2873  Loss_G: -0.6395  Loss_R_real: 0.0301  Loss_R_fake: 0.3842  D(x): 0.5417  D(G(z)): 0.4418  latent_norm : 15.0513  \n",
      "[14/55][400/1144]  Loss_D: 1.2854  Loss_G: -0.6368  Loss_R_real: 0.0290  Loss_R_fake: 0.3689  D(x): 0.4949  D(G(z)): 0.4261  latent_norm : 14.3940  \n",
      "[14/55][600/1144]  Loss_D: 1.2854  Loss_G: -0.6368  Loss_R_real: 0.0287  Loss_R_fake: 0.3722  D(x): 0.5317  D(G(z)): 0.4751  latent_norm : 15.0843  \n",
      "[14/55][800/1144]  Loss_D: 1.2844  Loss_G: -0.6361  Loss_R_real: 0.0285  Loss_R_fake: 0.3732  D(x): 0.5257  D(G(z)): 0.4339  latent_norm : 15.4387  \n",
      "[14/55][1000/1144]  Loss_D: 1.2841  Loss_G: -0.6359  Loss_R_real: 0.0287  Loss_R_fake: 0.3768  D(x): 0.5484  D(G(z)): 0.4714  latent_norm : 16.1457  \n",
      "Model successfully saved.\n",
      "[15/55][200/1144]  Loss_D: 1.2769  Loss_G: -0.6302  Loss_R_real: 0.0278  Loss_R_fake: 0.3892  D(x): 0.5294  D(G(z)): 0.4414  latent_norm : 14.7793  \n",
      "[15/55][400/1144]  Loss_D: 1.2748  Loss_G: -0.6295  Loss_R_real: 0.0271  Loss_R_fake: 0.3791  D(x): 0.5288  D(G(z)): 0.4832  latent_norm : 15.1298  \n",
      "[15/55][600/1144]  Loss_D: 1.2730  Loss_G: -0.6287  Loss_R_real: 0.0278  Loss_R_fake: 0.3819  D(x): 0.5698  D(G(z)): 0.4626  latent_norm : 15.4817  \n",
      "[15/55][800/1144]  Loss_D: 1.2714  Loss_G: -0.6280  Loss_R_real: 0.0280  Loss_R_fake: 0.3883  D(x): 0.5503  D(G(z)): 0.4354  latent_norm : 15.7582  \n",
      "[15/55][1000/1144]  Loss_D: 1.2702  Loss_G: -0.6276  Loss_R_real: 0.0283  Loss_R_fake: 0.3899  D(x): 0.5242  D(G(z)): 0.4305  latent_norm : 13.4959  \n",
      "Model successfully saved.\n",
      "[16/55][200/1144]  Loss_D: 1.2629  Loss_G: -0.6231  Loss_R_real: 0.0279  Loss_R_fake: 0.3648  D(x): 0.5627  D(G(z)): 0.4591  latent_norm : 16.3320  \n",
      "[16/55][400/1144]  Loss_D: 1.2606  Loss_G: -0.6226  Loss_R_real: 0.0288  Loss_R_fake: 0.3819  D(x): 0.5543  D(G(z)): 0.4515  latent_norm : 16.3721  \n",
      "[16/55][600/1144]  Loss_D: 1.2596  Loss_G: -0.6218  Loss_R_real: 0.0285  Loss_R_fake: 0.3873  D(x): 0.5492  D(G(z)): 0.4426  latent_norm : 15.1282  \n",
      "[16/55][800/1144]  Loss_D: 1.2581  Loss_G: -0.6210  Loss_R_real: 0.0288  Loss_R_fake: 0.3880  D(x): 0.5597  D(G(z)): 0.4522  latent_norm : 16.4406  \n",
      "[16/55][1000/1144]  Loss_D: 1.2575  Loss_G: -0.6206  Loss_R_real: 0.0286  Loss_R_fake: 0.3907  D(x): 0.5511  D(G(z)): 0.4271  latent_norm : 14.7457  \n",
      "Model successfully saved.\n",
      "[17/55][200/1144]  Loss_D: 1.2438  Loss_G: -0.6142  Loss_R_real: 0.0277  Loss_R_fake: 0.4020  D(x): 0.5396  D(G(z)): 0.4609  latent_norm : 14.2105  \n",
      "[17/55][400/1144]  Loss_D: 1.2440  Loss_G: -0.6139  Loss_R_real: 0.0276  Loss_R_fake: 0.4013  D(x): 0.5148  D(G(z)): 0.4348  latent_norm : 12.4290  \n",
      "[17/55][600/1144]  Loss_D: 1.2458  Loss_G: -0.6144  Loss_R_real: 0.0276  Loss_R_fake: 0.3970  D(x): 0.5604  D(G(z)): 0.4308  latent_norm : 14.3025  \n",
      "[17/55][800/1144]  Loss_D: 1.2454  Loss_G: -0.6137  Loss_R_real: 0.0280  Loss_R_fake: 0.3963  D(x): 0.5632  D(G(z)): 0.4533  latent_norm : 14.9582  \n",
      "[17/55][1000/1144]  Loss_D: 1.2462  Loss_G: -0.6142  Loss_R_real: 0.0281  Loss_R_fake: 0.3944  D(x): 0.5713  D(G(z)): 0.4277  latent_norm : 14.0386  \n",
      "Model successfully saved.\n",
      "[18/55][200/1144]  Loss_D: 1.2343  Loss_G: -0.6071  Loss_R_real: 0.0289  Loss_R_fake: 0.4201  D(x): 0.5655  D(G(z)): 0.4271  latent_norm : 15.3151  \n",
      "[18/55][400/1144]  Loss_D: 1.2329  Loss_G: -0.6065  Loss_R_real: 0.0278  Loss_R_fake: 0.4164  D(x): 0.5592  D(G(z)): 0.4444  latent_norm : 16.2470  \n",
      "[18/55][600/1144]  Loss_D: 1.2352  Loss_G: -0.6077  Loss_R_real: 0.0281  Loss_R_fake: 0.4179  D(x): 0.5109  D(G(z)): 0.4282  latent_norm : 14.7449  \n",
      "[18/55][800/1144]  Loss_D: 1.2348  Loss_G: -0.6074  Loss_R_real: 0.0284  Loss_R_fake: 0.4203  D(x): 0.5608  D(G(z)): 0.4674  latent_norm : 14.1808  \n",
      "[18/55][1000/1144]  Loss_D: 1.2343  Loss_G: -0.6074  Loss_R_real: 0.0284  Loss_R_fake: 0.4203  D(x): 0.5896  D(G(z)): 0.4602  latent_norm : 15.2335  \n",
      "Model successfully saved.\n",
      "[19/55][200/1144]  Loss_D: 1.2249  Loss_G: -0.6019  Loss_R_real: 0.0279  Loss_R_fake: 0.4445  D(x): 0.5050  D(G(z)): 0.4114  latent_norm : 12.7384  \n",
      "[19/55][400/1144]  Loss_D: 1.2243  Loss_G: -0.6015  Loss_R_real: 0.0279  Loss_R_fake: 0.4360  D(x): 0.5669  D(G(z)): 0.4370  latent_norm : 15.7728  \n",
      "[19/55][600/1144]  Loss_D: 1.2236  Loss_G: -0.6011  Loss_R_real: 0.0282  Loss_R_fake: 0.4344  D(x): 0.5389  D(G(z)): 0.4376  latent_norm : 13.3656  \n",
      "[19/55][800/1144]  Loss_D: 1.2219  Loss_G: -0.6004  Loss_R_real: 0.0285  Loss_R_fake: 0.4321  D(x): 0.5565  D(G(z)): 0.4653  latent_norm : 16.0425  \n",
      "[19/55][1000/1144]  Loss_D: 1.2224  Loss_G: -0.6007  Loss_R_real: 0.0282  Loss_R_fake: 0.4307  D(x): 0.5480  D(G(z)): 0.4397  latent_norm : 13.6451  \n",
      "Model successfully saved.\n",
      "[20/55][200/1144]  Loss_D: 1.2160  Loss_G: -0.5984  Loss_R_real: 0.0296  Loss_R_fake: 0.4204  D(x): 0.5803  D(G(z)): 0.4714  latent_norm : 15.5811  \n",
      "[20/55][400/1144]  Loss_D: 1.2137  Loss_G: -0.5960  Loss_R_real: 0.0288  Loss_R_fake: 0.4174  D(x): 0.5578  D(G(z)): 0.4322  latent_norm : 14.4506  \n",
      "[20/55][600/1144]  Loss_D: 1.2126  Loss_G: -0.5955  Loss_R_real: 0.0283  Loss_R_fake: 0.4184  D(x): 0.5410  D(G(z)): 0.4539  latent_norm : 15.3243  \n",
      "[20/55][800/1144]  Loss_D: 1.2129  Loss_G: -0.5956  Loss_R_real: 0.0287  Loss_R_fake: 0.4221  D(x): 0.5478  D(G(z)): 0.4589  latent_norm : 13.8608  \n",
      "[20/55][1000/1144]  Loss_D: 1.2132  Loss_G: -0.5954  Loss_R_real: 0.0285  Loss_R_fake: 0.4224  D(x): 0.5721  D(G(z)): 0.4599  latent_norm : 14.5102  \n",
      "Model successfully saved.\n",
      "[21/55][200/1144]  Loss_D: 1.1968  Loss_G: -0.5880  Loss_R_real: 0.0292  Loss_R_fake: 0.4072  D(x): 0.5399  D(G(z)): 0.4605  latent_norm : 16.0762  \n",
      "[21/55][400/1144]  Loss_D: 1.1976  Loss_G: -0.5878  Loss_R_real: 0.0290  Loss_R_fake: 0.4229  D(x): 0.6108  D(G(z)): 0.4647  latent_norm : 15.0689  \n",
      "[21/55][600/1144]  Loss_D: 1.1991  Loss_G: -0.5883  Loss_R_real: 0.0289  Loss_R_fake: 0.4357  D(x): 0.5416  D(G(z)): 0.4161  latent_norm : 14.2766  \n",
      "[21/55][800/1144]  Loss_D: 1.1999  Loss_G: -0.5884  Loss_R_real: 0.0287  Loss_R_fake: 0.4311  D(x): 0.5670  D(G(z)): 0.4413  latent_norm : 15.9816  \n",
      "[21/55][1000/1144]  Loss_D: 1.1990  Loss_G: -0.5875  Loss_R_real: 0.0287  Loss_R_fake: 0.4317  D(x): 0.5828  D(G(z)): 0.4671  latent_norm : 14.4933  \n",
      "Model successfully saved.\n",
      "[22/55][200/1144]  Loss_D: 1.1762  Loss_G: -0.5747  Loss_R_real: 0.0286  Loss_R_fake: 0.4739  D(x): 0.6112  D(G(z)): 0.4347  latent_norm : 15.7050  \n",
      "[22/55][400/1144]  Loss_D: 1.1836  Loss_G: -0.5792  Loss_R_real: 0.0284  Loss_R_fake: 0.4496  D(x): 0.6154  D(G(z)): 0.4064  latent_norm : 17.5921  \n",
      "[22/55][600/1144]  Loss_D: 1.1843  Loss_G: -0.5791  Loss_R_real: 0.0288  Loss_R_fake: 0.4529  D(x): 0.5901  D(G(z)): 0.4504  latent_norm : 16.0603  \n",
      "[22/55][800/1144]  Loss_D: 1.1833  Loss_G: -0.5790  Loss_R_real: 0.0285  Loss_R_fake: 0.4465  D(x): 0.6221  D(G(z)): 0.4026  latent_norm : 15.2950  \n",
      "[22/55][1000/1144]  Loss_D: 1.1854  Loss_G: -0.5797  Loss_R_real: 0.0286  Loss_R_fake: 0.4484  D(x): 0.5496  D(G(z)): 0.4228  latent_norm : 14.2545  \n",
      "Model successfully saved.\n",
      "[23/55][200/1144]  Loss_D: 1.1711  Loss_G: -0.5747  Loss_R_real: 0.0288  Loss_R_fake: 0.4589  D(x): 0.5367  D(G(z)): 0.3831  latent_norm : 14.3774  \n",
      "[23/55][400/1144]  Loss_D: 1.1737  Loss_G: -0.5745  Loss_R_real: 0.0287  Loss_R_fake: 0.4532  D(x): 0.6309  D(G(z)): 0.4117  latent_norm : 14.0592  \n",
      "[23/55][600/1144]  Loss_D: 1.1721  Loss_G: -0.5730  Loss_R_real: 0.0291  Loss_R_fake: 0.4528  D(x): 0.5380  D(G(z)): 0.4204  latent_norm : 14.0114  \n",
      "[23/55][800/1144]  Loss_D: 1.1745  Loss_G: -0.5742  Loss_R_real: 0.0288  Loss_R_fake: 0.4507  D(x): 0.5613  D(G(z)): 0.4008  latent_norm : 15.4816  \n",
      "[23/55][1000/1144]  Loss_D: 1.1747  Loss_G: -0.5743  Loss_R_real: 0.0289  Loss_R_fake: 0.4519  D(x): 0.5584  D(G(z)): 0.4325  latent_norm : 13.9977  \n",
      "Model successfully saved.\n",
      "[24/55][200/1144]  Loss_D: 1.1642  Loss_G: -0.5700  Loss_R_real: 0.0295  Loss_R_fake: 0.4248  D(x): 0.6146  D(G(z)): 0.4331  latent_norm : 13.9990  \n",
      "[24/55][400/1144]  Loss_D: 1.1633  Loss_G: -0.5685  Loss_R_real: 0.0286  Loss_R_fake: 0.4346  D(x): 0.6402  D(G(z)): 0.4148  latent_norm : 14.8916  \n",
      "[24/55][600/1144]  Loss_D: 1.1640  Loss_G: -0.5683  Loss_R_real: 0.0285  Loss_R_fake: 0.4455  D(x): 0.5950  D(G(z)): 0.4326  latent_norm : 15.5359  \n",
      "[24/55][800/1144]  Loss_D: 1.1644  Loss_G: -0.5686  Loss_R_real: 0.0285  Loss_R_fake: 0.4412  D(x): 0.6214  D(G(z)): 0.4349  latent_norm : 15.1349  \n",
      "[24/55][1000/1144]  Loss_D: 1.1647  Loss_G: -0.5685  Loss_R_real: 0.0286  Loss_R_fake: 0.4435  D(x): 0.6355  D(G(z)): 0.3947  latent_norm : 14.9239  \n",
      "Model successfully saved.\n",
      "[25/55][200/1144]  Loss_D: 1.1543  Loss_G: -0.5627  Loss_R_real: 0.0279  Loss_R_fake: 0.4091  D(x): 0.5678  D(G(z)): 0.4088  latent_norm : 16.0183  \n",
      "[25/55][400/1144]  Loss_D: 1.1571  Loss_G: -0.5645  Loss_R_real: 0.0285  Loss_R_fake: 0.4207  D(x): 0.5856  D(G(z)): 0.3939  latent_norm : 14.9426  \n",
      "[25/55][600/1144]  Loss_D: 1.1567  Loss_G: -0.5639  Loss_R_real: 0.0287  Loss_R_fake: 0.4397  D(x): 0.5618  D(G(z)): 0.4205  latent_norm : 15.8038  \n",
      "[25/55][800/1144]  Loss_D: 1.1552  Loss_G: -0.5631  Loss_R_real: 0.0290  Loss_R_fake: 0.4412  D(x): 0.5827  D(G(z)): 0.4165  latent_norm : 13.5452  \n",
      "[25/55][1000/1144]  Loss_D: 1.1553  Loss_G: -0.5630  Loss_R_real: 0.0286  Loss_R_fake: 0.4458  D(x): 0.5529  D(G(z)): 0.4029  latent_norm : 14.4153  \n",
      "Model successfully saved.\n",
      "[26/55][200/1144]  Loss_D: 1.1354  Loss_G: -0.5533  Loss_R_real: 0.0298  Loss_R_fake: 0.4413  D(x): 0.5991  D(G(z)): 0.4215  latent_norm : 15.2337  \n",
      "[26/55][400/1144]  Loss_D: 1.1403  Loss_G: -0.5549  Loss_R_real: 0.0288  Loss_R_fake: 0.4383  D(x): 0.5966  D(G(z)): 0.3888  latent_norm : 14.7616  \n",
      "[26/55][600/1144]  Loss_D: 1.1411  Loss_G: -0.5556  Loss_R_real: 0.0292  Loss_R_fake: 0.4377  D(x): 0.5985  D(G(z)): 0.4125  latent_norm : 15.1759  \n",
      "[26/55][800/1144]  Loss_D: 1.1420  Loss_G: -0.5559  Loss_R_real: 0.0294  Loss_R_fake: 0.4415  D(x): 0.5681  D(G(z)): 0.4065  latent_norm : 14.3460  \n",
      "[26/55][1000/1144]  Loss_D: 1.1420  Loss_G: -0.5558  Loss_R_real: 0.0290  Loss_R_fake: 0.4436  D(x): 0.6474  D(G(z)): 0.3649  latent_norm : 15.9128  \n",
      "Model successfully saved.\n",
      "[27/55][200/1144]  Loss_D: 1.1317  Loss_G: -0.5521  Loss_R_real: 0.0287  Loss_R_fake: 0.4302  D(x): 0.6646  D(G(z)): 0.3936  latent_norm : 15.7359  \n",
      "[27/55][400/1144]  Loss_D: 1.1309  Loss_G: -0.5508  Loss_R_real: 0.0288  Loss_R_fake: 0.4313  D(x): 0.5599  D(G(z)): 0.3720  latent_norm : 14.2237  \n",
      "[27/55][600/1144]  Loss_D: 1.1291  Loss_G: -0.5500  Loss_R_real: 0.0294  Loss_R_fake: 0.4268  D(x): 0.6090  D(G(z)): 0.4524  latent_norm : 15.6366  \n",
      "[27/55][800/1144]  Loss_D: 1.1296  Loss_G: -0.5497  Loss_R_real: 0.0290  Loss_R_fake: 0.4318  D(x): 0.5675  D(G(z)): 0.3957  latent_norm : 15.0548  \n",
      "[27/55][1000/1144]  Loss_D: 1.1292  Loss_G: -0.5499  Loss_R_real: 0.0291  Loss_R_fake: 0.4349  D(x): 0.6234  D(G(z)): 0.4239  latent_norm : 14.5983  \n",
      "Model successfully saved.\n",
      "[28/55][200/1144]  Loss_D: 1.1100  Loss_G: -0.5393  Loss_R_real: 0.0287  Loss_R_fake: 0.4489  D(x): 0.5603  D(G(z)): 0.3776  latent_norm : 15.0978  \n",
      "[28/55][400/1144]  Loss_D: 1.1150  Loss_G: -0.5418  Loss_R_real: 0.0298  Loss_R_fake: 0.4491  D(x): 0.5670  D(G(z)): 0.4117  latent_norm : 14.7222  \n",
      "[28/55][600/1144]  Loss_D: 1.1178  Loss_G: -0.5427  Loss_R_real: 0.0295  Loss_R_fake: 0.4492  D(x): 0.5736  D(G(z)): 0.3713  latent_norm : 15.6693  \n",
      "[28/55][800/1144]  Loss_D: 1.1179  Loss_G: -0.5427  Loss_R_real: 0.0297  Loss_R_fake: 0.4482  D(x): 0.5843  D(G(z)): 0.4228  latent_norm : 14.5495  \n",
      "[28/55][1000/1144]  Loss_D: 1.1185  Loss_G: -0.5431  Loss_R_real: 0.0295  Loss_R_fake: 0.4514  D(x): 0.5657  D(G(z)): 0.3848  latent_norm : 14.6844  \n",
      "Model successfully saved.\n",
      "[29/55][200/1144]  Loss_D: 1.0901  Loss_G: -0.5289  Loss_R_real: 0.0297  Loss_R_fake: 0.4705  D(x): 0.6297  D(G(z)): 0.3409  latent_norm : 16.6476  \n",
      "[29/55][400/1144]  Loss_D: 1.0986  Loss_G: -0.5337  Loss_R_real: 0.0285  Loss_R_fake: 0.4546  D(x): 0.5928  D(G(z)): 0.4232  latent_norm : 14.1160  \n",
      "[29/55][600/1144]  Loss_D: 1.1004  Loss_G: -0.5340  Loss_R_real: 0.0286  Loss_R_fake: 0.4623  D(x): 0.5779  D(G(z)): 0.3855  latent_norm : 14.8102  \n",
      "[29/55][800/1144]  Loss_D: 1.1051  Loss_G: -0.5359  Loss_R_real: 0.0289  Loss_R_fake: 0.4572  D(x): 0.5809  D(G(z)): 0.3911  latent_norm : 13.9379  \n",
      "[29/55][1000/1144]  Loss_D: 1.1058  Loss_G: -0.5363  Loss_R_real: 0.0292  Loss_R_fake: 0.4573  D(x): 0.6094  D(G(z)): 0.3728  latent_norm : 15.1513  \n",
      "Model successfully saved.\n",
      "[30/55][200/1144]  Loss_D: 1.0870  Loss_G: -0.5272  Loss_R_real: 0.0281  Loss_R_fake: 0.4199  D(x): 0.5765  D(G(z)): 0.3984  latent_norm : 13.8588  \n",
      "[30/55][400/1144]  Loss_D: 1.0884  Loss_G: -0.5284  Loss_R_real: 0.0278  Loss_R_fake: 0.4261  D(x): 0.6102  D(G(z)): 0.4300  latent_norm : 15.2766  \n",
      "[30/55][600/1144]  Loss_D: 1.0918  Loss_G: -0.5296  Loss_R_real: 0.0284  Loss_R_fake: 0.4335  D(x): 0.6373  D(G(z)): 0.4100  latent_norm : 16.0530  \n",
      "[30/55][800/1144]  Loss_D: 1.0936  Loss_G: -0.5302  Loss_R_real: 0.0289  Loss_R_fake: 0.4381  D(x): 0.6141  D(G(z)): 0.4029  latent_norm : 15.1497  \n",
      "[30/55][1000/1144]  Loss_D: 1.0975  Loss_G: -0.5322  Loss_R_real: 0.0289  Loss_R_fake: 0.4405  D(x): 0.7004  D(G(z)): 0.3820  latent_norm : 14.4891  \n",
      "Model successfully saved.\n",
      "[31/55][200/1144]  Loss_D: 1.0802  Loss_G: -0.5226  Loss_R_real: 0.0312  Loss_R_fake: 0.4625  D(x): 0.5299  D(G(z)): 0.4058  latent_norm : 13.1733  \n",
      "[31/55][400/1144]  Loss_D: 1.0810  Loss_G: -0.5240  Loss_R_real: 0.0295  Loss_R_fake: 0.4594  D(x): 0.5999  D(G(z)): 0.4132  latent_norm : 15.6450  \n",
      "[31/55][600/1144]  Loss_D: 1.0872  Loss_G: -0.5265  Loss_R_real: 0.0295  Loss_R_fake: 0.4533  D(x): 0.5978  D(G(z)): 0.4185  latent_norm : 14.2583  \n",
      "[31/55][800/1144]  Loss_D: 1.0861  Loss_G: -0.5261  Loss_R_real: 0.0291  Loss_R_fake: 0.4507  D(x): 0.6523  D(G(z)): 0.3910  latent_norm : 14.5774  \n",
      "[31/55][1000/1144]  Loss_D: 1.0864  Loss_G: -0.5261  Loss_R_real: 0.0294  Loss_R_fake: 0.4547  D(x): 0.5986  D(G(z)): 0.4344  latent_norm : 13.7912  \n",
      "Model successfully saved.\n",
      "[32/55][200/1144]  Loss_D: 1.0684  Loss_G: -0.5167  Loss_R_real: 0.0292  Loss_R_fake: 0.4591  D(x): 0.6185  D(G(z)): 0.4453  latent_norm : 14.8500  \n",
      "[32/55][400/1144]  Loss_D: 1.0730  Loss_G: -0.5186  Loss_R_real: 0.0286  Loss_R_fake: 0.4435  D(x): 0.6544  D(G(z)): 0.4002  latent_norm : 14.1998  \n",
      "[32/55][600/1144]  Loss_D: 1.0745  Loss_G: -0.5199  Loss_R_real: 0.0295  Loss_R_fake: 0.4556  D(x): 0.5904  D(G(z)): 0.3746  latent_norm : 15.0275  \n",
      "[32/55][800/1144]  Loss_D: 1.0755  Loss_G: -0.5207  Loss_R_real: 0.0289  Loss_R_fake: 0.4610  D(x): 0.6198  D(G(z)): 0.3701  latent_norm : 14.0674  \n",
      "[32/55][1000/1144]  Loss_D: 1.0767  Loss_G: -0.5211  Loss_R_real: 0.0287  Loss_R_fake: 0.4610  D(x): 0.5949  D(G(z)): 0.3698  latent_norm : 14.4930  \n",
      "Model successfully saved.\n",
      "[33/55][200/1144]  Loss_D: 1.0566  Loss_G: -0.5121  Loss_R_real: 0.0297  Loss_R_fake: 0.4663  D(x): 0.6212  D(G(z)): 0.3541  latent_norm : 15.3399  \n",
      "[33/55][400/1144]  Loss_D: 1.0575  Loss_G: -0.5119  Loss_R_real: 0.0298  Loss_R_fake: 0.4541  D(x): 0.6490  D(G(z)): 0.3633  latent_norm : 14.8364  \n",
      "[33/55][600/1144]  Loss_D: 1.0611  Loss_G: -0.5138  Loss_R_real: 0.0292  Loss_R_fake: 0.4551  D(x): 0.6300  D(G(z)): 0.4035  latent_norm : 16.5533  \n",
      "[33/55][800/1144]  Loss_D: 1.0609  Loss_G: -0.5131  Loss_R_real: 0.0292  Loss_R_fake: 0.4560  D(x): 0.5690  D(G(z)): 0.3692  latent_norm : 14.3028  \n",
      "[33/55][1000/1144]  Loss_D: 1.0635  Loss_G: -0.5143  Loss_R_real: 0.0290  Loss_R_fake: 0.4563  D(x): 0.6177  D(G(z)): 0.4411  latent_norm : 15.4661  \n",
      "Model successfully saved.\n",
      "[34/55][200/1144]  Loss_D: 1.0452  Loss_G: -0.5059  Loss_R_real: 0.0288  Loss_R_fake: 0.4395  D(x): 0.6630  D(G(z)): 0.3481  latent_norm : 15.4922  \n",
      "[34/55][400/1144]  Loss_D: 1.0502  Loss_G: -0.5074  Loss_R_real: 0.0300  Loss_R_fake: 0.4582  D(x): 0.6081  D(G(z)): 0.3448  latent_norm : 14.6562  \n",
      "[34/55][600/1144]  Loss_D: 1.0491  Loss_G: -0.5070  Loss_R_real: 0.0302  Loss_R_fake: 0.4575  D(x): 0.6854  D(G(z)): 0.3849  latent_norm : 15.4952  \n",
      "[34/55][800/1144]  Loss_D: 1.0492  Loss_G: -0.5070  Loss_R_real: 0.0295  Loss_R_fake: 0.4597  D(x): 0.5637  D(G(z)): 0.3741  latent_norm : 14.0368  \n",
      "[34/55][1000/1144]  Loss_D: 1.0510  Loss_G: -0.5081  Loss_R_real: 0.0299  Loss_R_fake: 0.4599  D(x): 0.5712  D(G(z)): 0.3868  latent_norm : 15.8541  \n",
      "Model successfully saved.\n",
      "[35/55][200/1144]  Loss_D: 1.0319  Loss_G: -0.4971  Loss_R_real: 0.0298  Loss_R_fake: 0.4803  D(x): 0.6494  D(G(z)): 0.3555  latent_norm : 14.6158  \n",
      "[35/55][400/1144]  Loss_D: 1.0387  Loss_G: -0.5010  Loss_R_real: 0.0297  Loss_R_fake: 0.4691  D(x): 0.6364  D(G(z)): 0.3718  latent_norm : 15.2535  \n",
      "[35/55][600/1144]  Loss_D: 1.0401  Loss_G: -0.5014  Loss_R_real: 0.0297  Loss_R_fake: 0.4603  D(x): 0.5789  D(G(z)): 0.3558  latent_norm : 14.3205  \n",
      "[35/55][800/1144]  Loss_D: 1.0406  Loss_G: -0.5015  Loss_R_real: 0.0294  Loss_R_fake: 0.4587  D(x): 0.6395  D(G(z)): 0.4194  latent_norm : 12.9699  \n",
      "[35/55][1000/1144]  Loss_D: 1.0420  Loss_G: -0.5021  Loss_R_real: 0.0291  Loss_R_fake: 0.4525  D(x): 0.6287  D(G(z)): 0.4326  latent_norm : 14.8508  \n",
      "Model successfully saved.\n",
      "[36/55][200/1144]  Loss_D: 1.0374  Loss_G: -0.5014  Loss_R_real: 0.0289  Loss_R_fake: 0.4486  D(x): 0.6448  D(G(z)): 0.3158  latent_norm : 14.7980  \n",
      "[36/55][400/1144]  Loss_D: 1.0392  Loss_G: -0.5016  Loss_R_real: 0.0289  Loss_R_fake: 0.4455  D(x): 0.6536  D(G(z)): 0.3476  latent_norm : 15.0499  \n",
      "[36/55][600/1144]  Loss_D: 1.0369  Loss_G: -0.5000  Loss_R_real: 0.0296  Loss_R_fake: 0.4459  D(x): 0.6679  D(G(z)): 0.3484  latent_norm : 16.6649  \n",
      "[36/55][800/1144]  Loss_D: 1.0378  Loss_G: -0.5000  Loss_R_real: 0.0298  Loss_R_fake: 0.4515  D(x): 0.6763  D(G(z)): 0.3601  latent_norm : 15.9580  \n",
      "[36/55][1000/1144]  Loss_D: 1.0367  Loss_G: -0.4999  Loss_R_real: 0.0297  Loss_R_fake: 0.4510  D(x): 0.6082  D(G(z)): 0.3626  latent_norm : 13.8100  \n",
      "Model successfully saved.\n",
      "[37/55][200/1144]  Loss_D: 1.0211  Loss_G: -0.4922  Loss_R_real: 0.0299  Loss_R_fake: 0.4309  D(x): 0.6343  D(G(z)): 0.4275  latent_norm : 14.4259  \n",
      "[37/55][400/1144]  Loss_D: 1.0183  Loss_G: -0.4914  Loss_R_real: 0.0292  Loss_R_fake: 0.4578  D(x): 0.6615  D(G(z)): 0.3415  latent_norm : 14.6047  \n",
      "[37/55][600/1144]  Loss_D: 1.0223  Loss_G: -0.4928  Loss_R_real: 0.0292  Loss_R_fake: 0.4653  D(x): 0.6095  D(G(z)): 0.3647  latent_norm : 14.5852  \n",
      "[37/55][800/1144]  Loss_D: 1.0252  Loss_G: -0.4942  Loss_R_real: 0.0294  Loss_R_fake: 0.4620  D(x): 0.6317  D(G(z)): 0.3477  latent_norm : 14.4634  \n",
      "[37/55][1000/1144]  Loss_D: 1.0234  Loss_G: -0.4932  Loss_R_real: 0.0295  Loss_R_fake: 0.4567  D(x): 0.6420  D(G(z)): 0.3167  latent_norm : 15.8514  \n",
      "Model successfully saved.\n",
      "[38/55][200/1144]  Loss_D: 1.0052  Loss_G: -0.4858  Loss_R_real: 0.0283  Loss_R_fake: 0.4295  D(x): 0.6481  D(G(z)): 0.3102  latent_norm : 14.4773  \n",
      "[38/55][400/1144]  Loss_D: 1.0034  Loss_G: -0.4853  Loss_R_real: 0.0291  Loss_R_fake: 0.4383  D(x): 0.6884  D(G(z)): 0.3400  latent_norm : 13.9385  \n",
      "[38/55][600/1144]  Loss_D: 1.0060  Loss_G: -0.4854  Loss_R_real: 0.0299  Loss_R_fake: 0.4401  D(x): 0.6416  D(G(z)): 0.3583  latent_norm : 13.9900  \n",
      "[38/55][800/1144]  Loss_D: 1.0067  Loss_G: -0.4855  Loss_R_real: 0.0298  Loss_R_fake: 0.4424  D(x): 0.6131  D(G(z)): 0.3632  latent_norm : 16.6950  \n",
      "[38/55][1000/1144]  Loss_D: 1.0109  Loss_G: -0.4875  Loss_R_real: 0.0299  Loss_R_fake: 0.4388  D(x): 0.5834  D(G(z)): 0.3392  latent_norm : 13.3106  \n",
      "Model successfully saved.\n",
      "[39/55][200/1144]  Loss_D: 0.9826  Loss_G: -0.4757  Loss_R_real: 0.0285  Loss_R_fake: 0.4449  D(x): 0.6916  D(G(z)): 0.3351  latent_norm : 14.8383  \n",
      "[39/55][400/1144]  Loss_D: 0.9940  Loss_G: -0.4801  Loss_R_real: 0.0286  Loss_R_fake: 0.4506  D(x): 0.5965  D(G(z)): 0.3035  latent_norm : 15.7253  \n",
      "[39/55][600/1144]  Loss_D: 0.9968  Loss_G: -0.4816  Loss_R_real: 0.0296  Loss_R_fake: 0.4471  D(x): 0.6716  D(G(z)): 0.3461  latent_norm : 15.0489  \n",
      "[39/55][800/1144]  Loss_D: 0.9986  Loss_G: -0.4822  Loss_R_real: 0.0297  Loss_R_fake: 0.4502  D(x): 0.6113  D(G(z)): 0.3588  latent_norm : 14.0336  \n",
      "[39/55][1000/1144]  Loss_D: 0.9999  Loss_G: -0.4821  Loss_R_real: 0.0299  Loss_R_fake: 0.4489  D(x): 0.6580  D(G(z)): 0.3376  latent_norm : 15.0357  \n",
      "Model successfully saved.\n",
      "[40/55][200/1144]  Loss_D: 0.9807  Loss_G: -0.4737  Loss_R_real: 0.0304  Loss_R_fake: 0.4339  D(x): 0.5702  D(G(z)): 0.3877  latent_norm : 12.7564  \n",
      "[40/55][400/1144]  Loss_D: 0.9850  Loss_G: -0.4760  Loss_R_real: 0.0310  Loss_R_fake: 0.4401  D(x): 0.6480  D(G(z)): 0.3687  latent_norm : 14.6247  \n",
      "[40/55][600/1144]  Loss_D: 0.9918  Loss_G: -0.4787  Loss_R_real: 0.0300  Loss_R_fake: 0.4443  D(x): 0.6653  D(G(z)): 0.3353  latent_norm : 15.4695  \n",
      "[40/55][800/1144]  Loss_D: 0.9935  Loss_G: -0.4790  Loss_R_real: 0.0300  Loss_R_fake: 0.4500  D(x): 0.6468  D(G(z)): 0.3662  latent_norm : 14.5067  \n",
      "[40/55][1000/1144]  Loss_D: 0.9943  Loss_G: -0.4790  Loss_R_real: 0.0300  Loss_R_fake: 0.4411  D(x): 0.6250  D(G(z)): 0.4244  latent_norm : 12.6968  \n",
      "Model successfully saved.\n",
      "[41/55][200/1144]  Loss_D: 0.9690  Loss_G: -0.4684  Loss_R_real: 0.0317  Loss_R_fake: 0.4550  D(x): 0.6235  D(G(z)): 0.3969  latent_norm : 13.3676  \n",
      "[41/55][400/1144]  Loss_D: 0.9794  Loss_G: -0.4730  Loss_R_real: 0.0299  Loss_R_fake: 0.4617  D(x): 0.6768  D(G(z)): 0.4217  latent_norm : 14.8042  \n",
      "[41/55][600/1144]  Loss_D: 0.9800  Loss_G: -0.4724  Loss_R_real: 0.0298  Loss_R_fake: 0.4622  D(x): 0.6357  D(G(z)): 0.3433  latent_norm : 15.3994  \n",
      "[41/55][800/1144]  Loss_D: 0.9821  Loss_G: -0.4730  Loss_R_real: 0.0303  Loss_R_fake: 0.4588  D(x): 0.5880  D(G(z)): 0.3285  latent_norm : 14.3207  \n",
      "[41/55][1000/1144]  Loss_D: 0.9848  Loss_G: -0.4745  Loss_R_real: 0.0304  Loss_R_fake: 0.4554  D(x): 0.6277  D(G(z)): 0.3297  latent_norm : 13.9476  \n",
      "Model successfully saved.\n",
      "[42/55][200/1144]  Loss_D: 0.9467  Loss_G: -0.4579  Loss_R_real: 0.0288  Loss_R_fake: 0.4738  D(x): 0.7476  D(G(z)): 0.2799  latent_norm : 14.7653  \n",
      "[42/55][400/1144]  Loss_D: 0.9586  Loss_G: -0.4619  Loss_R_real: 0.0297  Loss_R_fake: 0.4526  D(x): 0.6460  D(G(z)): 0.3093  latent_norm : 14.7806  \n",
      "[42/55][600/1144]  Loss_D: 0.9625  Loss_G: -0.4637  Loss_R_real: 0.0293  Loss_R_fake: 0.4407  D(x): 0.6283  D(G(z)): 0.3802  latent_norm : 15.3700  \n",
      "[42/55][800/1144]  Loss_D: 0.9635  Loss_G: -0.4641  Loss_R_real: 0.0294  Loss_R_fake: 0.4487  D(x): 0.6735  D(G(z)): 0.3561  latent_norm : 15.6900  \n",
      "[42/55][1000/1144]  Loss_D: 0.9679  Loss_G: -0.4659  Loss_R_real: 0.0296  Loss_R_fake: 0.4504  D(x): 0.7068  D(G(z)): 0.3072  latent_norm : 15.9816  \n",
      "Model successfully saved.\n",
      "[43/55][200/1144]  Loss_D: 0.9486  Loss_G: -0.4570  Loss_R_real: 0.0277  Loss_R_fake: 0.4509  D(x): 0.6395  D(G(z)): 0.3504  latent_norm : 15.2024  \n",
      "[43/55][400/1144]  Loss_D: 0.9560  Loss_G: -0.4600  Loss_R_real: 0.0296  Loss_R_fake: 0.4597  D(x): 0.6521  D(G(z)): 0.2904  latent_norm : 13.3787  \n",
      "[43/55][600/1144]  Loss_D: 0.9582  Loss_G: -0.4608  Loss_R_real: 0.0299  Loss_R_fake: 0.4461  D(x): 0.6350  D(G(z)): 0.3263  latent_norm : 14.4975  \n",
      "[43/55][800/1144]  Loss_D: 0.9610  Loss_G: -0.4620  Loss_R_real: 0.0299  Loss_R_fake: 0.4471  D(x): 0.6651  D(G(z)): 0.3514  latent_norm : 16.5133  \n",
      "[43/55][1000/1144]  Loss_D: 0.9636  Loss_G: -0.4632  Loss_R_real: 0.0300  Loss_R_fake: 0.4545  D(x): 0.6696  D(G(z)): 0.2884  latent_norm : 13.9646  \n",
      "Model successfully saved.\n",
      "[44/55][200/1144]  Loss_D: 0.9411  Loss_G: -0.4517  Loss_R_real: 0.0291  Loss_R_fake: 0.4388  D(x): 0.6759  D(G(z)): 0.3731  latent_norm : 14.8617  \n",
      "[44/55][400/1144]  Loss_D: 0.9478  Loss_G: -0.4552  Loss_R_real: 0.0296  Loss_R_fake: 0.4531  D(x): 0.6567  D(G(z)): 0.3301  latent_norm : 14.9999  \n",
      "[44/55][600/1144]  Loss_D: 0.9502  Loss_G: -0.4568  Loss_R_real: 0.0297  Loss_R_fake: 0.4588  D(x): 0.7068  D(G(z)): 0.3434  latent_norm : 16.2924  \n",
      "[44/55][800/1144]  Loss_D: 0.9530  Loss_G: -0.4582  Loss_R_real: 0.0294  Loss_R_fake: 0.4549  D(x): 0.6309  D(G(z)): 0.2564  latent_norm : 15.1198  \n",
      "[44/55][1000/1144]  Loss_D: 0.9537  Loss_G: -0.4585  Loss_R_real: 0.0294  Loss_R_fake: 0.4570  D(x): 0.6365  D(G(z)): 0.3062  latent_norm : 14.8174  \n",
      "Model successfully saved.\n",
      "[45/55][200/1144]  Loss_D: 0.9251  Loss_G: -0.4441  Loss_R_real: 0.0302  Loss_R_fake: 0.4418  D(x): 0.6611  D(G(z)): 0.3516  latent_norm : 15.0902  \n",
      "[45/55][400/1144]  Loss_D: 0.9331  Loss_G: -0.4490  Loss_R_real: 0.0295  Loss_R_fake: 0.4344  D(x): 0.6641  D(G(z)): 0.3803  latent_norm : 16.2440  \n",
      "[45/55][600/1144]  Loss_D: 0.9356  Loss_G: -0.4498  Loss_R_real: 0.0308  Loss_R_fake: 0.4506  D(x): 0.7199  D(G(z)): 0.3464  latent_norm : 15.5198  \n",
      "[45/55][800/1144]  Loss_D: 0.9387  Loss_G: -0.4513  Loss_R_real: 0.0309  Loss_R_fake: 0.4558  D(x): 0.6434  D(G(z)): 0.3493  latent_norm : 14.8282  \n",
      "[45/55][1000/1144]  Loss_D: 0.9412  Loss_G: -0.4521  Loss_R_real: 0.0306  Loss_R_fake: 0.4538  D(x): 0.6169  D(G(z)): 0.3370  latent_norm : 13.6019  \n",
      "Model successfully saved.\n",
      "[46/55][200/1144]  Loss_D: 0.9188  Loss_G: -0.4431  Loss_R_real: 0.0307  Loss_R_fake: 0.4252  D(x): 0.6962  D(G(z)): 0.3216  latent_norm : 14.0851  \n",
      "[46/55][400/1144]  Loss_D: 0.9278  Loss_G: -0.4463  Loss_R_real: 0.0307  Loss_R_fake: 0.4349  D(x): 0.7106  D(G(z)): 0.3039  latent_norm : 15.6213  \n",
      "[46/55][600/1144]  Loss_D: 0.9291  Loss_G: -0.4467  Loss_R_real: 0.0309  Loss_R_fake: 0.4436  D(x): 0.6776  D(G(z)): 0.3280  latent_norm : 15.9185  \n",
      "[46/55][800/1144]  Loss_D: 0.9334  Loss_G: -0.4491  Loss_R_real: 0.0304  Loss_R_fake: 0.4466  D(x): 0.6579  D(G(z)): 0.3182  latent_norm : 14.4085  \n",
      "[46/55][1000/1144]  Loss_D: 0.9333  Loss_G: -0.4494  Loss_R_real: 0.0307  Loss_R_fake: 0.4475  D(x): 0.7377  D(G(z)): 0.2862  latent_norm : 15.5306  \n",
      "Model successfully saved.\n",
      "[47/55][200/1144]  Loss_D: 0.9182  Loss_G: -0.4411  Loss_R_real: 0.0300  Loss_R_fake: 0.4751  D(x): 0.6164  D(G(z)): 0.3514  latent_norm : 14.0358  \n",
      "[47/55][400/1144]  Loss_D: 0.9198  Loss_G: -0.4421  Loss_R_real: 0.0305  Loss_R_fake: 0.4644  D(x): 0.6347  D(G(z)): 0.3259  latent_norm : 14.5756  \n",
      "[47/55][600/1144]  Loss_D: 0.9202  Loss_G: -0.4416  Loss_R_real: 0.0308  Loss_R_fake: 0.4627  D(x): 0.6664  D(G(z)): 0.3177  latent_norm : 14.7938  \n",
      "[47/55][800/1144]  Loss_D: 0.9203  Loss_G: -0.4424  Loss_R_real: 0.0309  Loss_R_fake: 0.4626  D(x): 0.7015  D(G(z)): 0.3256  latent_norm : 15.6980  \n",
      "[47/55][1000/1144]  Loss_D: 0.9213  Loss_G: -0.4426  Loss_R_real: 0.0315  Loss_R_fake: 0.4687  D(x): 0.6551  D(G(z)): 0.3218  latent_norm : 16.3602  \n",
      "Model successfully saved.\n",
      "[48/55][200/1144]  Loss_D: 0.8982  Loss_G: -0.4327  Loss_R_real: 0.0303  Loss_R_fake: 0.4549  D(x): 0.6637  D(G(z)): 0.3926  latent_norm : 14.1298  \n",
      "[48/55][400/1144]  Loss_D: 0.9054  Loss_G: -0.4355  Loss_R_real: 0.0297  Loss_R_fake: 0.4540  D(x): 0.6708  D(G(z)): 0.3599  latent_norm : 16.7157  \n",
      "[48/55][600/1144]  Loss_D: 0.9080  Loss_G: -0.4365  Loss_R_real: 0.0301  Loss_R_fake: 0.4685  D(x): 0.7624  D(G(z)): 0.3081  latent_norm : 16.5758  \n",
      "[48/55][800/1144]  Loss_D: 0.9139  Loss_G: -0.4391  Loss_R_real: 0.0301  Loss_R_fake: 0.4548  D(x): 0.6664  D(G(z)): 0.3154  latent_norm : 14.4238  \n",
      "[48/55][1000/1144]  Loss_D: 0.9148  Loss_G: -0.4398  Loss_R_real: 0.0301  Loss_R_fake: 0.4563  D(x): 0.7006  D(G(z)): 0.3490  latent_norm : 15.1271  \n",
      "Model successfully saved.\n",
      "[49/55][200/1144]  Loss_D: 0.8952  Loss_G: -0.4321  Loss_R_real: 0.0307  Loss_R_fake: 0.4480  D(x): 0.7516  D(G(z)): 0.3201  latent_norm : 16.3290  \n",
      "[49/55][400/1144]  Loss_D: 0.9009  Loss_G: -0.4341  Loss_R_real: 0.0310  Loss_R_fake: 0.4374  D(x): 0.6485  D(G(z)): 0.3130  latent_norm : 15.0708  \n",
      "[49/55][600/1144]  Loss_D: 0.9020  Loss_G: -0.4348  Loss_R_real: 0.0307  Loss_R_fake: 0.4433  D(x): 0.7020  D(G(z)): 0.2882  latent_norm : 13.9860  \n",
      "[49/55][800/1144]  Loss_D: 0.9041  Loss_G: -0.4346  Loss_R_real: 0.0307  Loss_R_fake: 0.4530  D(x): 0.7208  D(G(z)): 0.3450  latent_norm : 15.3791  \n",
      "[49/55][1000/1144]  Loss_D: 0.9054  Loss_G: -0.4354  Loss_R_real: 0.0306  Loss_R_fake: 0.4576  D(x): 0.6218  D(G(z)): 0.3198  latent_norm : 14.5820  \n",
      "Model successfully saved.\n",
      "[50/55][200/1144]  Loss_D: 0.8830  Loss_G: -0.4254  Loss_R_real: 0.0297  Loss_R_fake: 0.4510  D(x): 0.7603  D(G(z)): 0.3071  latent_norm : 16.5483  \n",
      "[50/55][400/1144]  Loss_D: 0.8850  Loss_G: -0.4259  Loss_R_real: 0.0302  Loss_R_fake: 0.4455  D(x): 0.7477  D(G(z)): 0.3325  latent_norm : 13.6959  \n",
      "[50/55][600/1144]  Loss_D: 0.8909  Loss_G: -0.4287  Loss_R_real: 0.0305  Loss_R_fake: 0.4488  D(x): 0.7121  D(G(z)): 0.3148  latent_norm : 15.1755  \n",
      "[50/55][800/1144]  Loss_D: 0.8906  Loss_G: -0.4283  Loss_R_real: 0.0306  Loss_R_fake: 0.4476  D(x): 0.7161  D(G(z)): 0.2900  latent_norm : 15.0823  \n",
      "[50/55][1000/1144]  Loss_D: 0.8941  Loss_G: -0.4301  Loss_R_real: 0.0308  Loss_R_fake: 0.4446  D(x): 0.7225  D(G(z)): 0.3167  latent_norm : 15.0103  \n",
      "Model successfully saved.\n",
      "[51/55][200/1144]  Loss_D: 0.8748  Loss_G: -0.4215  Loss_R_real: 0.0301  Loss_R_fake: 0.4451  D(x): 0.6969  D(G(z)): 0.3041  latent_norm : 14.3685  \n",
      "[51/55][400/1144]  Loss_D: 0.8810  Loss_G: -0.4250  Loss_R_real: 0.0307  Loss_R_fake: 0.4509  D(x): 0.7435  D(G(z)): 0.3369  latent_norm : 14.5832  \n",
      "[51/55][600/1144]  Loss_D: 0.8843  Loss_G: -0.4260  Loss_R_real: 0.0304  Loss_R_fake: 0.4517  D(x): 0.7018  D(G(z)): 0.2658  latent_norm : 15.5870  \n",
      "[51/55][800/1144]  Loss_D: 0.8823  Loss_G: -0.4251  Loss_R_real: 0.0304  Loss_R_fake: 0.4508  D(x): 0.7423  D(G(z)): 0.3041  latent_norm : 15.2657  \n",
      "[51/55][1000/1144]  Loss_D: 0.8861  Loss_G: -0.4264  Loss_R_real: 0.0309  Loss_R_fake: 0.4580  D(x): 0.6984  D(G(z)): 0.2757  latent_norm : 16.3638  \n",
      "Model successfully saved.\n",
      "[52/55][200/1144]  Loss_D: 0.8639  Loss_G: -0.4159  Loss_R_real: 0.0303  Loss_R_fake: 0.4705  D(x): 0.6891  D(G(z)): 0.3046  latent_norm : 13.9039  \n",
      "[52/55][400/1144]  Loss_D: 0.8652  Loss_G: -0.4156  Loss_R_real: 0.0312  Loss_R_fake: 0.4637  D(x): 0.7100  D(G(z)): 0.3563  latent_norm : 15.0249  \n",
      "[52/55][600/1144]  Loss_D: 0.8712  Loss_G: -0.4191  Loss_R_real: 0.0308  Loss_R_fake: 0.4487  D(x): 0.7437  D(G(z)): 0.3497  latent_norm : 15.5494  \n",
      "[52/55][800/1144]  Loss_D: 0.8722  Loss_G: -0.4195  Loss_R_real: 0.0311  Loss_R_fake: 0.4460  D(x): 0.6963  D(G(z)): 0.3021  latent_norm : 15.0566  \n",
      "[52/55][1000/1144]  Loss_D: 0.8765  Loss_G: -0.4212  Loss_R_real: 0.0312  Loss_R_fake: 0.4547  D(x): 0.7258  D(G(z)): 0.3157  latent_norm : 13.4106  \n",
      "Model successfully saved.\n",
      "[53/55][200/1144]  Loss_D: 0.8539  Loss_G: -0.4100  Loss_R_real: 0.0317  Loss_R_fake: 0.4516  D(x): 0.7296  D(G(z)): 0.3328  latent_norm : 15.7329  \n",
      "[53/55][400/1144]  Loss_D: 0.8556  Loss_G: -0.4112  Loss_R_real: 0.0307  Loss_R_fake: 0.4567  D(x): 0.7201  D(G(z)): 0.2568  latent_norm : 15.5844  \n",
      "[53/55][600/1144]  Loss_D: 0.8626  Loss_G: -0.4145  Loss_R_real: 0.0310  Loss_R_fake: 0.4552  D(x): 0.7194  D(G(z)): 0.2823  latent_norm : 15.1730  \n",
      "[53/55][800/1144]  Loss_D: 0.8657  Loss_G: -0.4164  Loss_R_real: 0.0309  Loss_R_fake: 0.4571  D(x): 0.7573  D(G(z)): 0.3552  latent_norm : 14.9444  \n",
      "[53/55][1000/1144]  Loss_D: 0.8670  Loss_G: -0.4166  Loss_R_real: 0.0309  Loss_R_fake: 0.4584  D(x): 0.7359  D(G(z)): 0.3051  latent_norm : 14.9354  \n",
      "Model successfully saved.\n",
      "[54/55][200/1144]  Loss_D: 0.8517  Loss_G: -0.4107  Loss_R_real: 0.0307  Loss_R_fake: 0.4307  D(x): 0.6594  D(G(z)): 0.3073  latent_norm : 14.1629  \n",
      "[54/55][400/1144]  Loss_D: 0.8546  Loss_G: -0.4119  Loss_R_real: 0.0312  Loss_R_fake: 0.4486  D(x): 0.6680  D(G(z)): 0.2305  latent_norm : 14.3416  \n",
      "[54/55][600/1144]  Loss_D: 0.8550  Loss_G: -0.4111  Loss_R_real: 0.0313  Loss_R_fake: 0.4520  D(x): 0.7128  D(G(z)): 0.3450  latent_norm : 15.3274  \n",
      "[54/55][800/1144]  Loss_D: 0.8584  Loss_G: -0.4125  Loss_R_real: 0.0311  Loss_R_fake: 0.4506  D(x): 0.7219  D(G(z)): 0.2899  latent_norm : 15.3677  \n",
      "[54/55][1000/1144]  Loss_D: 0.8588  Loss_G: -0.4124  Loss_R_real: 0.0313  Loss_R_fake: 0.4493  D(x): 0.7106  D(G(z)): 0.2769  latent_norm : 14.7043  \n",
      "Model successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# Enable anomaly detection during training (optional)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(len(d_losses), opt.niter):\n",
    "    \n",
    "    # Initialize lists to store losses and other metrics\n",
    "    store_loss_D = []\n",
    "    store_loss_G = []\n",
    "    store_loss_R_real = []\n",
    "    store_loss_R_fake = []\n",
    "    store_norm = []\n",
    "    store_kl = []\n",
    "\n",
    "    # Iterate over the data batches\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # Wake (W)\n",
    "        ###########################\n",
    "\n",
    "        # Discrimination wake\n",
    "        discriminator_optimizer .zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Fetch real images and labels\n",
    "        real_image, label = data\n",
    "        real_image, label = real_image.to(device), label.to(device)\n",
    "\n",
    "        # Pass real images through the discriminator\n",
    "        latent_output, dis_output = discriminator(real_image)\n",
    "\n",
    "        # Add noise to the latent space\n",
    "        latent_output_noise = latent_output + opt.epsilon * torch.randn(batch_size, latent_size, device=device)\n",
    "\n",
    "        # Set the discriminator label for real images\n",
    "        discriminator_label[:] = real_label_value\n",
    "\n",
    "        # Compute the discriminator loss for real images\n",
    "        dis_errD_real = discriminator_criterion(dis_output, discriminator_label)\n",
    "\n",
    "        if opt.R > 0.0:  # if GAN learning occurs\n",
    "            (dis_errD_real).backward(retain_graph=True)\n",
    "\n",
    "        # Compute the KL divergence regularization loss\n",
    "        kl = kl_loss(latent_output)\n",
    "        (kl).backward(retain_graph=True)\n",
    "\n",
    "        # Reconstruct real images from the latent space\n",
    "        reconstructed_image = generator(latent_output_noise, reverse=False)\n",
    "\n",
    "        # Compute the reconstruction loss for real images\n",
    "        rec_real = reconstruction_criterion (reconstructed_image, real_image)\n",
    "\n",
    "        if opt.W > 0.0:\n",
    "            (opt.W * rec_real).backward()\n",
    "\n",
    "        discriminator_optimizer .step()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Compute the mean of the discriminator output (between 0 and 1)\n",
    "        D_x = dis_output.cpu().mean()\n",
    "\n",
    "        # Compute the norm of the latent space representation\n",
    "        latent_norm = torch.mean(torch.norm(latent_output.squeeze(), dim=1)).item()\n",
    "\n",
    "\n",
    "        ###########################\n",
    "        # NREM perturbed dreaming (N)\n",
    "        ##########################\n",
    "        discriminator_optimizer .zero_grad()\n",
    "\n",
    "        # Detach the latent space representation\n",
    "        latent_z = latent_output.detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Generate images from the detached latent space\n",
    "            nrem_image = generator(latent_z)\n",
    "\n",
    "            # Apply occlusion to the generated images\n",
    "            occlusion = Occlude(drop_rate=random.random(), tile_size=random.randint(1, 8))\n",
    "            occluded_nrem_image = occlusion(nrem_image, dim=1)\n",
    "\n",
    "        # Pass occluded NREM images through the discriminator\n",
    "        latent_recons_dream, _ = discriminator(occluded_nrem_image)\n",
    "\n",
    "        # Compute the reconstruction loss for fake images\n",
    "        rec_fake = reconstruction_criterion (latent_recons_dream, latent_output.detach())\n",
    "\n",
    "        if opt.N > 0.0:\n",
    "            (opt.N * rec_fake).backward()\n",
    "\n",
    "        discriminator_optimizer .step()\n",
    "\n",
    "\n",
    "       ###########################\n",
    "        # REM adversarial dreaming (R)\n",
    "        ##########################\n",
    "\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        lmbd = opt.lmbd\n",
    "        noise = torch.randn(batch_size, latent_size, device=device)\n",
    "        if i==0:\n",
    "            latent_z = 0.5*latent_output.detach() + 0.5*noise\n",
    "        else:\n",
    "            latent_z = 0.25*latent_output.detach() + 0.25*old_latent_output + 0.5*noise\n",
    "        \n",
    "        dreamed_image_adv = generator(latent_z, reverse=True) # activate plasticity switch\n",
    "        latent_recons_dream, dis_output = discriminator(dreamed_image_adv)\n",
    "        discriminator_label[:] = fake_label_value # should be classified as fake\n",
    "        dis_errD_fake = discriminator_criterion(dis_output, discriminator_label)\n",
    "        if opt.R > 0.0: # if GAN learning occurs\n",
    "            dis_errD_fake.backward(retain_graph=True)\n",
    "            discriminator_optimizer.step()\n",
    "            generator_optimizer.step()\n",
    "        dis_errG = - dis_errD_fake\n",
    "\n",
    "        D_G_z1 = dis_output.cpu().mean()\n",
    "\n",
    "        old_latent_output = latent_output.detach()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###########################\n",
    "        # Compute average losses\n",
    "        ###########################\n",
    "        store_loss_G.append(dis_errG.item())\n",
    "        store_loss_D.append((dis_errD_fake + dis_errD_real).item())\n",
    "        store_loss_R_real.append(rec_real.item())\n",
    "        store_loss_R_fake.append(rec_fake.item())\n",
    "        store_norm.append(latent_norm)\n",
    "        store_kl.append(kl.item())\n",
    "        \n",
    "\n",
    "\n",
    "        if i % 200 == 0 and i>1:\n",
    "            print('[%d/%d][%d/%d]  Loss_D: %.4f  Loss_G: %.4f  Loss_R_real: %.4f  Loss_R_fake: %.4f  D(x): %.4f  D(G(z)): %.4f  latent_norm : %.4f  '\n",
    "                % (epoch, opt.niter, i, len(dataloader),\n",
    "                    np.mean(store_loss_D), np.mean(store_loss_G), np.mean(store_loss_R_real), np.mean(store_loss_R_fake), D_x, D_G_z1, np.mean(latent_norm) ))\n",
    "            compare_img_rec = torch.zeros(batch_size * 2, real_image.size(1), real_image.size(2), real_image.size(3))\n",
    "            with torch.no_grad():\n",
    "                reconstructed_image = generator(latent_output)\n",
    "            compare_img_rec[::2] = real_image\n",
    "            compare_img_rec[1::2] = reconstructed_image\n",
    "            vutils.save_image(unorm(compare_img_rec[:128]), '%s/recon_%03d.png' % (dir_files, epoch), nrow=8)\n",
    "            fake = unorm(dreamed_image_adv)\n",
    "            vutils.save_image(fake[:64].data, '%s/fake_%03d.png' % (dir_files, epoch), nrow=8)\n",
    "            \n",
    "\n",
    "    d_losses.append(np.mean(store_loss_D))\n",
    "    g_losses.append(np.mean(store_loss_G))\n",
    "    r_losses_real.append(np.mean(store_loss_R_real))\n",
    "    r_losses_fake.append(np.mean(store_loss_R_fake))\n",
    "    kl_losses.append(np.mean(store_kl))\n",
    "    save_fig_losses(epoch, d_losses, g_losses, r_losses_real, r_losses_fake, kl_losses, None, None,  dir_files)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save({\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'g_optim': generator_optimizer.state_dict(),\n",
    "        'd_optim': discriminator_optimizer.state_dict(),\n",
    "        'd_losses': d_losses,\n",
    "        'g_losses': g_losses,\n",
    "        'r_losses_real': r_losses_real,\n",
    "        'r_losses_fake': r_losses_fake,\n",
    "        'kl_losses': kl_losses,\n",
    "    }, dir_checkpoint+'/trained.pth')\n",
    "    \n",
    "    # save network after 1 learning epoch\n",
    "    if epoch ==1:\n",
    "            torch.save({\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        }, dir_checkpoint+'/trained2.pth')\n",
    "\n",
    "    print(f'Model successfully saved.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
