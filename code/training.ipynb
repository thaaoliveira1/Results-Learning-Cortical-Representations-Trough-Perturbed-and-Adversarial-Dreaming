{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function  # Ensures print function compatibility with Python 2.x\n",
    "import argparse  # Library for parsing command-line arguments\n",
    "import os  # Library for interacting with the operating system\n",
    "import copy  # Library for creating object copies\n",
    "import numpy as np  # Numerical computing library\n",
    "import random  # Library for generating random numbers\n",
    "\n",
    "import torch  # Core library for PyTorch\n",
    "import torch.nn as nn  # Library for defining neural network components\n",
    "import torch.nn.parallel  # Library for parallelizing operations on multiple GPUs\n",
    "import torch.backends.cudnn as cudnn  # Interface to the cuDNN library for GPU optimizations\n",
    "import torch.optim as optim  # Library for optimization algorithms\n",
    "import torch.utils.data  # Tools for working with datasets in PyTorch\n",
    "import torchvision.datasets as dset  # Datasets provided by torchvision\n",
    "import torchvision.transforms as transforms  # Transformations for image preprocessing\n",
    "import torchvision.utils as vutils  # Utility functions for visualizing images\n",
    "from torch.autograd import Variable  # Provides automatic differentiation for tensors\n",
    "import torch.nn.functional as F  # Library for various activation functions and loss functions\n",
    "\n",
    "from functions import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(imageSize=32, dataset='mnist', dataroot='./datasets/', num_workers=2, is_continue=1, batch_size=64, image_size=32, latent_size=256, num_epochs=55, weight_cycle_consistency=1.0, W=1.0, N=1.0, R=1.0, epsilon=0.0, num_filters=64, dropout_prob=0.0, learning_rate_generator=0.0002, learning_rate_discriminator=0.0002, beta1=0.5, lmbd=0.5, num_gpus=1, output_folder='output', gpu_id='0', outf='output', niter=55)\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import argparse\n",
    "\n",
    "# Creating an argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Adding arguments with their default values and descriptions\n",
    "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to network')\n",
    "parser.add_argument('--dataset', default='mnist', help='Dataset to use: cifar10 | svnh | mnist')\n",
    "parser.add_argument('--dataroot', default='./datasets/', help='Path to the dataset')\n",
    "parser.add_argument('--num_workers', type=int, help='Number of data loading workers', default=2)\n",
    "parser.add_argument('--is_continue', type=int, default=1, help='Use pre-trained model')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Input batch size')\n",
    "parser.add_argument('--image_size', type=int, default=32, help='Height/width of the input image to the network')\n",
    "parser.add_argument('--latent_size', type=int, default=256, help='Size of the latent vector')\n",
    "parser.add_argument('--num_epochs', type=int, default=55, help='Number of epochs to train for')\n",
    "parser.add_argument('--weight_cycle_consistency', type=float, default=1.0, help='Weight of Cycle Consistency')\n",
    "parser.add_argument('--W', type=float, default=1.0, help='Wake')\n",
    "parser.add_argument('--N', type=float, default=1.0, help='NREM')\n",
    "parser.add_argument('--R', type=float, default=1.0, help='REM')\n",
    "parser.add_argument('--epsilon', type=float, default=0.0, help='Amount of noise in the wake latent space')\n",
    "parser.add_argument('--num_filters', type=int, default=64, help='Filters factor')\n",
    "parser.add_argument('--dropout_prob', type=float, default=0.0, help='Probability of dropout')\n",
    "parser.add_argument('--learning_rate_generator', type=float, default=0.0002, help='Learning rate for the generator')\n",
    "parser.add_argument('--learning_rate_discriminator', type=float, default=0.0002, help='Learning rate for the discriminator')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='Beta1 for Adam optimizer')\n",
    "parser.add_argument('--lmbd', type=float, default=0.5, help='convex combination factor for REM')\n",
    "parser.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use')\n",
    "parser.add_argument('--output_folder', default='output', help='Folder to output images and model checkpoints')\n",
    "parser.add_argument('--gpu_id', type=str, default='0', help='The ID of the specified GPU')\n",
    "parser.add_argument('--outf', default='output', help='folder to output images and model checkpoints')\n",
    "\n",
    "\n",
    "\n",
    "# Parsing the command-line arguments\n",
    "opt, unknown = parser.parse_known_args()\n",
    "\n",
    "# Set the number of iterations to the number of epochs\n",
    "opt.niter = opt.num_epochs\n",
    "\n",
    "# Assign the value of latent_size based on opt.latent_size\n",
    "latent_size = opt.latent_size\n",
    "\n",
    "# Printing the parsed arguments\n",
    "print(opt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. The code begins by importing the necessary library, **`argparse`**, which provides a way to parse command-line arguments.\n",
    "\n",
    "2. An argument parser object is created using **`argparse.ArgumentParser()`**. This object will handle the parsing of command-line arguments.\n",
    "\n",
    "3. Various arguments are added to the parser using the **`add_argument()`** method. Each argument has a unique name, a default value, and a description.\n",
    "\n",
    "4. The command-line arguments are parsed using **`parser.parse_known_args()`**, which returns two values: **`opt`** (containing the parsed argument values) and **`unknown`** (containing any unrecognized arguments).\n",
    "\n",
    "5. The parsed argument values are stored in the **`opt`** object.\n",
    "\n",
    "6. Finally, the values of the parsed arguments are printed using **`print(opt)`**.\n",
    "\n",
    "This code allows you to run the program with different options and values from the command line. Each option represents a specific setting or parameter that can be customized. The **`argparse`** library handles the parsing of these options, and the **`opt`** object stores the values for further use within the program. Printing the **`opt`** object provides a summary of the parsed argument values, allowing you to verify the settings before running the main logic of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU ID if using only 1 GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
    "\n",
    "# where to save samples and training curves\n",
    "dir_files = './results/'+opt.dataset+'/'+opt.outf\n",
    "# where to save model\n",
    "dir_checkpoint = './checkpoints/'+opt.dataset+'/'+opt.outf\n",
    "\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "try:\n",
    "    os.makedirs(dir_files)\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(dir_checkpoint)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Set the device to CUDA if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the dataset and get relevant information\n",
    "dataset, unorm, img_channels = get_dataset(opt.dataset, opt.dataroot, opt.imageSize)\n",
    "\n",
    "# Create a data loader for loading the dataset in batches\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "                                         num_workers=int(opt.num_workers), drop_last=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code sets the environment variable **`CUDA_VISIBLE_DEVICES`** to the GPU ID specified in **`opt.gpu_id`**. This ensures that only the specified GPU is used when running the program.\n",
    "\n",
    "2. The code defines two directory paths: **`dir_files`** for saving samples and training curves, and **`dir_checkpoint`** for saving models.\n",
    "\n",
    "3. The code attempts to create the directories specified by **`dir_files`** and **`dir_checkpoint`**. If the directories already exist, the **`OSError`** exception is caught and passed.\n",
    "\n",
    "4. The code checks if CUDA is available and assigns the device accordingly. If CUDA is available, the device is set to the GPU with ID 0; otherwise, it is set to CPU.\n",
    "\n",
    "5. The code calls the **`get_dataset()`** function to load the dataset specified in **`opt.dataset`** from the directory **`opt.dataroot`**, and also obtains the **`unorm`** (normalization) and **`img_channels`** (number of image channels) values.\n",
    "\n",
    "6. Finally, the code creates a **`DataLoader`** object called **`dataloader`**, which allows iterating over the dataset in batches. The batch size is specified by **`opt.batchSize`**, and the data is shuffled and loaded in parallel using **`opt.num_workers`** worker processes. The **`drop_last`** option ensures that the last incomplete batch is dropped if its size is less than **`opt.batchSize`**.\n",
    "\n",
    "This code prepares the necessary setup before training the neural network, such as configuring the device, setting up directories for saving results, and loading the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): Flatten()\n",
       "  )\n",
       "  (dis): Sequential(\n",
       "    (0): Conv2d(256, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): Flatten()\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and assign values to hyperparameters\n",
    "num_gpus = int(opt.num_gpus)\n",
    "latent_dim = int(opt.latent_size)\n",
    "batch_size = opt.batch_size\n",
    "\n",
    "# Instantiate generator and discriminator networks\n",
    "generator = Generator(num_gpus, latent_dim=latent_dim, ngf=opt.num_filters, img_channels=img_channels)\n",
    "generator.apply(initialize_weights)\n",
    "discriminator = Discriminator(num_gpus, latent_dim=latent_dim, ndf=opt.num_filters, img_channels=img_channels, dropout_prob=opt.dropout_prob)\n",
    "discriminator.apply(initialize_weights)\n",
    "\n",
    "\n",
    "# Move networks to the GPU\n",
    "generator.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The code sets up some hyperparameters, such as the number of GPUs available (num_gpus), the size of the latent space (latent_dim), and the batch size (batch_size).\n",
    "\n",
    "2. Two neural network models are instantiated: the generator (named \"generator\") and the discriminator (named \"discriminator\").\n",
    "\n",
    "3. The generator is an instance of the Generator class, which takes the number of GPUs, latent dimension, number of filters, and number of channels as arguments.\n",
    "\n",
    "4. The discriminator is an instance of the Discriminator class, which takes similar arguments as the generator along with a dropout probability.\n",
    "\n",
    "5. Weight initialization is applied to both the generator and discriminator using the weights_init function.\n",
    "\n",
    "6. The generator and discriminator models are moved to the specified device (e.g., GPU) using the to() method.\n",
    "\n",
    "7. This ensures that the computations for these models will be performed on the GPU if available, which can significantly speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizers for discriminator and generator\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=opt.learning_rate_discriminator, betas=(opt.beta1, 0.999))\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=opt.learning_rate_generator, betas=(opt.beta1, 0.999))\n",
    "\n",
    "# Initialize lists to store losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "r_losses_real = []\n",
    "r_losses_fake = []\n",
    "kl_losses = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sets up optimizers for the discriminator and generator models.\n",
    "\n",
    "1. The discriminator_optimizer uses the Adam optimizer and takes the discriminator parameters, learning rate (lrD), and beta values as arguments.\n",
    "\n",
    "2. The generator_optimizer uses the Adam optimizer and takes the generator parameters, learning rate (lrG), and beta values as arguments.\n",
    "\n",
    "3. Lists are initialized to store various types of losses during training.\n",
    "\n",
    "4. **discriminator_losses:** Stores the losses of the discriminator model.\n",
    "\n",
    "5. **generator_losses:** Stores the losses of the generator model.\n",
    "\n",
    "6. **real_losses:** Stores losses related to real images.\n",
    "\n",
    "7. **fake_losses:** Stores losses related to fake/generated images.\n",
    "\n",
    "8. **kl_losses:** Stores Kullback-Leibler divergence losses, which are often used in variational autoencoders (VAEs) or other generative models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model detected, restart training...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(dir_checkpoint+'/trained.pth') and opt.is_continue:\n",
    "    # Load data from last checkpoint\n",
    "    print('Loading pre-trained model...')\n",
    "    checkpoint = torch.load(dir_checkpoint+'/trained.pth', map_location=torch.device('cpu'))\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    generator_optimizer.load_state_dict(checkpoint['g_optim'])\n",
    "    discriminator_optimizer.load_state_dict(checkpoint['d_optim'])\n",
    "    d_losses = checkpoint.get('d_losses', [float('inf')])\n",
    "    g_losses = checkpoint.get('g_losses', [float('inf')])\n",
    "    r_losses_real = checkpoint.get('r_losses_real', [float('inf')])\n",
    "    r_losses_fake = checkpoint.get('r_losses_fake', [float('inf')])\n",
    "    kl_losses = checkpoint.get('kl_losses', [float('inf')])\n",
    "    print('Start training from loaded model...')\n",
    "else:\n",
    "    print('No pre-trained model detected, restart training...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions\n",
    "discriminator_criterion = nn.BCELoss()  # Binary Cross Entropy Loss for the discriminator\n",
    "reconstruction_criterion = nn.MSELoss()  # Mean Squared Error Loss for reconstruction\n",
    "\n",
    "# Create tensor placeholders\n",
    "discriminator_label = torch.zeros(opt.batch_size, dtype=torch.float32, device=device)\n",
    "real_label_value = 1.0\n",
    "fake_label_value = 0\n",
    "\n",
    "evaluation_noise = torch.randn(batch_size, latent_dim, device=device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "1. The code defines two loss functions: **`discriminator_criterion`** and **`reconstruction_criterion`**. The **`BCELoss`** (Binary Cross Entropy Loss) is used for the discriminator, and the **`MSELoss`** (Mean Squared Error Loss) is used for reconstruction.\n",
    "\n",
    "2. The variables **`dis_criterion`** and **`rec_criterion`** are changed to **`discriminator_criterion`** and **`reconstruction_criterion`**, respectively. \n",
    "\n",
    "3. The variable names **`dis_label`**, **`real_label_value`**, **`fake_label_value`**, and **`eval_noise`** are changed to **`discriminator_label`**, **`real_label_value`**, **`fake_label_value`**, and **`evaluation_noise`**, respectively.\n",
    "\n",
    "4. The order and structure of the code remain unchanged as they are necessary for defining the loss functions and creating tensor placeholders.\n",
    "\n",
    "Overall, this code snippet defines the loss functions for the discriminator and reconstruction tasks. The **`BCELoss`** is commonly used for binary classification tasks, such as determining whether an image is real or fake. The **`MSELoss`** is used for measuring the pixel-wise difference between the input and reconstructed images. The tensor placeholders are created to hold the discriminator labels, real and fake label values, and noise for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/55][200/937]  Loss_D: 1.3581  Loss_G: -0.7005  Loss_R_real: 0.3038  Loss_R_fake: 0.3916  D(x): 0.4945  D(G(z)): 0.5288  latent_norm : 13.3512  \n",
      "[0/55][400/937]  Loss_D: 1.3629  Loss_G: -0.6914  Loss_R_real: 0.2511  Loss_R_fake: 0.3776  D(x): 0.4709  D(G(z)): 0.5091  latent_norm : 14.1633  \n",
      "[0/55][600/937]  Loss_D: 1.3680  Loss_G: -0.6908  Loss_R_real: 0.2172  Loss_R_fake: 0.3677  D(x): 0.5065  D(G(z)): 0.4889  latent_norm : 12.6767  \n",
      "[0/55][800/937]  Loss_D: 1.3688  Loss_G: -0.6891  Loss_R_real: 0.1899  Loss_R_fake: 0.3417  D(x): 0.5108  D(G(z)): 0.4949  latent_norm : 12.6464  \n",
      "Model successfully saved.\n",
      "[1/55][200/937]  Loss_D: 1.3712  Loss_G: -0.6928  Loss_R_real: 0.0815  Loss_R_fake: 0.3044  D(x): 0.5149  D(G(z)): 0.4963  latent_norm : 12.6454  \n",
      "[1/55][400/937]  Loss_D: 1.3712  Loss_G: -0.6920  Loss_R_real: 0.0777  Loss_R_fake: 0.3061  D(x): 0.5011  D(G(z)): 0.4996  latent_norm : 13.1184  \n",
      "[1/55][600/937]  Loss_D: 1.3686  Loss_G: -0.6908  Loss_R_real: 0.0752  Loss_R_fake: 0.2954  D(x): 0.5100  D(G(z)): 0.5077  latent_norm : 15.1281  \n",
      "[1/55][800/937]  Loss_D: 1.3663  Loss_G: -0.6894  Loss_R_real: 0.0731  Loss_R_fake: 0.2982  D(x): 0.5057  D(G(z)): 0.4908  latent_norm : 14.4510  \n",
      "Model successfully saved.\n",
      "[2/55][200/937]  Loss_D: 1.3446  Loss_G: -0.6776  Loss_R_real: 0.0644  Loss_R_fake: 0.2878  D(x): 0.5046  D(G(z)): 0.4915  latent_norm : 14.3688  \n",
      "[2/55][400/937]  Loss_D: 1.3395  Loss_G: -0.6743  Loss_R_real: 0.0623  Loss_R_fake: 0.2782  D(x): 0.5165  D(G(z)): 0.4812  latent_norm : 13.1283  \n",
      "[2/55][600/937]  Loss_D: 1.3310  Loss_G: -0.6703  Loss_R_real: 0.0613  Loss_R_fake: 0.2846  D(x): 0.5418  D(G(z)): 0.4910  latent_norm : 15.5308  \n",
      "[2/55][800/937]  Loss_D: 1.3238  Loss_G: -0.6660  Loss_R_real: 0.0612  Loss_R_fake: 0.2851  D(x): 0.5464  D(G(z)): 0.4787  latent_norm : 15.4648  \n",
      "Model successfully saved.\n",
      "[3/55][200/937]  Loss_D: 1.2610  Loss_G: -0.6345  Loss_R_real: 0.0599  Loss_R_fake: 0.3124  D(x): 0.5384  D(G(z)): 0.4599  latent_norm : 15.3778  \n",
      "[3/55][400/937]  Loss_D: 1.2515  Loss_G: -0.6294  Loss_R_real: 0.0597  Loss_R_fake: 0.3057  D(x): 0.5324  D(G(z)): 0.4343  latent_norm : 14.4880  \n",
      "[3/55][600/937]  Loss_D: 1.2395  Loss_G: -0.6230  Loss_R_real: 0.0591  Loss_R_fake: 0.3246  D(x): 0.5447  D(G(z)): 0.4363  latent_norm : 15.9093  \n",
      "[3/55][800/937]  Loss_D: 1.2297  Loss_G: -0.6181  Loss_R_real: 0.0588  Loss_R_fake: 0.3193  D(x): 0.5819  D(G(z)): 0.4437  latent_norm : 15.3156  \n",
      "Model successfully saved.\n",
      "[4/55][200/937]  Loss_D: 1.1413  Loss_G: -0.5739  Loss_R_real: 0.0576  Loss_R_fake: 0.3061  D(x): 0.5550  D(G(z)): 0.4013  latent_norm : 14.9015  \n",
      "[4/55][400/937]  Loss_D: 1.1363  Loss_G: -0.5718  Loss_R_real: 0.0571  Loss_R_fake: 0.3273  D(x): 0.5970  D(G(z)): 0.4183  latent_norm : 14.7549  \n",
      "[4/55][600/937]  Loss_D: 1.1282  Loss_G: -0.5671  Loss_R_real: 0.0565  Loss_R_fake: 0.3221  D(x): 0.5393  D(G(z)): 0.3965  latent_norm : 15.6577  \n",
      "[4/55][800/937]  Loss_D: 1.1183  Loss_G: -0.5621  Loss_R_real: 0.0564  Loss_R_fake: 0.3185  D(x): 0.6272  D(G(z)): 0.3940  latent_norm : 15.4681  \n",
      "Model successfully saved.\n",
      "[5/55][200/937]  Loss_D: 1.0543  Loss_G: -0.5305  Loss_R_real: 0.0538  Loss_R_fake: 0.3072  D(x): 0.6171  D(G(z)): 0.3568  latent_norm : 15.7647  \n",
      "[5/55][400/937]  Loss_D: 1.0456  Loss_G: -0.5262  Loss_R_real: 0.0538  Loss_R_fake: 0.3299  D(x): 0.5921  D(G(z)): 0.3443  latent_norm : 16.7293  \n",
      "[5/55][600/937]  Loss_D: 1.0371  Loss_G: -0.5221  Loss_R_real: 0.0537  Loss_R_fake: 0.3379  D(x): 0.6409  D(G(z)): 0.2918  latent_norm : 15.2357  \n",
      "[5/55][800/937]  Loss_D: 1.0263  Loss_G: -0.5164  Loss_R_real: 0.0533  Loss_R_fake: 0.3371  D(x): 0.6502  D(G(z)): 0.3600  latent_norm : 14.7340  \n",
      "Model successfully saved.\n",
      "[6/55][200/937]  Loss_D: 0.9540  Loss_G: -0.4805  Loss_R_real: 0.0513  Loss_R_fake: 0.3369  D(x): 0.6428  D(G(z)): 0.3469  latent_norm : 14.5335  \n",
      "[6/55][400/937]  Loss_D: 0.9394  Loss_G: -0.4734  Loss_R_real: 0.0510  Loss_R_fake: 0.3468  D(x): 0.6689  D(G(z)): 0.3537  latent_norm : 16.2820  \n",
      "[6/55][600/937]  Loss_D: 0.9261  Loss_G: -0.4666  Loss_R_real: 0.0507  Loss_R_fake: 0.3543  D(x): 0.7236  D(G(z)): 0.2804  latent_norm : 16.4604  \n",
      "[6/55][800/937]  Loss_D: 0.9132  Loss_G: -0.4596  Loss_R_real: 0.0505  Loss_R_fake: 0.3604  D(x): 0.6552  D(G(z)): 0.3289  latent_norm : 15.0368  \n",
      "Model successfully saved.\n",
      "[7/55][200/937]  Loss_D: 0.8311  Loss_G: -0.4192  Loss_R_real: 0.0487  Loss_R_fake: 0.3664  D(x): 0.6218  D(G(z)): 0.2775  latent_norm : 14.0109  \n",
      "[7/55][400/937]  Loss_D: 0.8209  Loss_G: -0.4141  Loss_R_real: 0.0481  Loss_R_fake: 0.3551  D(x): 0.7075  D(G(z)): 0.2449  latent_norm : 15.3458  \n",
      "[7/55][600/937]  Loss_D: 0.8077  Loss_G: -0.4073  Loss_R_real: 0.0479  Loss_R_fake: 0.3526  D(x): 0.7528  D(G(z)): 0.2939  latent_norm : 16.2736  \n",
      "[7/55][800/937]  Loss_D: 0.7963  Loss_G: -0.4014  Loss_R_real: 0.0475  Loss_R_fake: 0.3607  D(x): 0.7000  D(G(z)): 0.2518  latent_norm : 16.4165  \n",
      "Model successfully saved.\n",
      "[8/55][200/937]  Loss_D: 0.7102  Loss_G: -0.3595  Loss_R_real: 0.0465  Loss_R_fake: 0.3412  D(x): 0.7551  D(G(z)): 0.2201  latent_norm : 14.9474  \n",
      "[8/55][400/937]  Loss_D: 0.7027  Loss_G: -0.3553  Loss_R_real: 0.0461  Loss_R_fake: 0.3639  D(x): 0.7262  D(G(z)): 0.2717  latent_norm : 16.7618  \n",
      "[8/55][600/937]  Loss_D: 0.6922  Loss_G: -0.3500  Loss_R_real: 0.0458  Loss_R_fake: 0.3661  D(x): 0.7044  D(G(z)): 0.2577  latent_norm : 15.0404  \n",
      "[8/55][800/937]  Loss_D: 0.6767  Loss_G: -0.3419  Loss_R_real: 0.0456  Loss_R_fake: 0.3629  D(x): 0.7620  D(G(z)): 0.2597  latent_norm : 15.1265  \n",
      "Model successfully saved.\n",
      "[9/55][200/937]  Loss_D: 0.5687  Loss_G: -0.2888  Loss_R_real: 0.0435  Loss_R_fake: 0.3567  D(x): 0.7980  D(G(z)): 0.2070  latent_norm : 15.2628  \n",
      "[9/55][400/937]  Loss_D: 0.5575  Loss_G: -0.2824  Loss_R_real: 0.0429  Loss_R_fake: 0.3559  D(x): 0.7806  D(G(z)): 0.1691  latent_norm : 15.7648  \n",
      "[9/55][600/937]  Loss_D: 0.5420  Loss_G: -0.2744  Loss_R_real: 0.0429  Loss_R_fake: 0.3676  D(x): 0.8412  D(G(z)): 0.1932  latent_norm : 15.8864  \n",
      "[9/55][800/937]  Loss_D: 0.5254  Loss_G: -0.2661  Loss_R_real: 0.0429  Loss_R_fake: 0.3615  D(x): 0.8356  D(G(z)): 0.1546  latent_norm : 16.3539  \n",
      "Model successfully saved.\n",
      "[10/55][200/937]  Loss_D: 0.4164  Loss_G: -0.2114  Loss_R_real: 0.0426  Loss_R_fake: 0.3658  D(x): 0.8567  D(G(z)): 0.1068  latent_norm : 15.3240  \n",
      "[10/55][400/937]  Loss_D: 0.3921  Loss_G: -0.1981  Loss_R_real: 0.0416  Loss_R_fake: 0.3889  D(x): 0.8739  D(G(z)): 0.1146  latent_norm : 15.8921  \n",
      "[10/55][600/937]  Loss_D: 0.3735  Loss_G: -0.1892  Loss_R_real: 0.0411  Loss_R_fake: 0.3882  D(x): 0.8618  D(G(z)): 0.1457  latent_norm : 15.9885  \n",
      "[10/55][800/937]  Loss_D: 0.3592  Loss_G: -0.1821  Loss_R_real: 0.0410  Loss_R_fake: 0.3798  D(x): 0.9016  D(G(z)): 0.1660  latent_norm : 15.1733  \n",
      "Model successfully saved.\n",
      "[11/55][200/937]  Loss_D: 0.3395  Loss_G: -0.1634  Loss_R_real: 0.0499  Loss_R_fake: 0.3955  D(x): 0.8846  D(G(z)): 0.0927  latent_norm : 15.6540  \n",
      "[11/55][400/937]  Loss_D: 0.2913  Loss_G: -0.1440  Loss_R_real: 0.0446  Loss_R_fake: 0.3880  D(x): 0.9749  D(G(z)): 0.0082  latent_norm : 15.6156  \n",
      "[11/55][600/937]  Loss_D: 0.2646  Loss_G: -0.1320  Loss_R_real: 0.0428  Loss_R_fake: 0.3767  D(x): 0.9154  D(G(z)): 0.0764  latent_norm : 16.1806  \n",
      "[11/55][800/937]  Loss_D: 0.2450  Loss_G: -0.1228  Loss_R_real: 0.0419  Loss_R_fake: 0.3777  D(x): 0.9272  D(G(z)): 0.0669  latent_norm : 15.1620  \n",
      "Model successfully saved.\n",
      "[12/55][200/937]  Loss_D: 0.1622  Loss_G: -0.0828  Loss_R_real: 0.0380  Loss_R_fake: 0.3557  D(x): 0.9113  D(G(z)): 0.0752  latent_norm : 15.6697  \n",
      "[12/55][400/937]  Loss_D: 0.1502  Loss_G: -0.0771  Loss_R_real: 0.0375  Loss_R_fake: 0.3610  D(x): 0.9178  D(G(z)): 0.0971  latent_norm : 16.1962  \n",
      "[12/55][600/937]  Loss_D: 0.1403  Loss_G: -0.0720  Loss_R_real: 0.0395  Loss_R_fake: 0.3599  D(x): 0.9966  D(G(z)): 0.0000  latent_norm : 15.5297  \n",
      "[12/55][800/937]  Loss_D: 0.1054  Loss_G: -0.0541  Loss_R_real: 0.0410  Loss_R_fake: 0.3517  D(x): 0.9867  D(G(z)): 0.0001  latent_norm : 15.1242  \n",
      "Model successfully saved.\n",
      "[13/55][200/937]  Loss_D: 0.2113  Loss_G: -0.1183  Loss_R_real: 0.0586  Loss_R_fake: 0.3994  D(x): 0.9569  D(G(z)): 0.0658  latent_norm : 15.8741  \n",
      "[13/55][400/937]  Loss_D: 0.1586  Loss_G: -0.0856  Loss_R_real: 0.0468  Loss_R_fake: 0.3818  D(x): 0.9240  D(G(z)): 0.0437  latent_norm : 15.3578  \n",
      "[13/55][600/937]  Loss_D: 0.1388  Loss_G: -0.0742  Loss_R_real: 0.0423  Loss_R_fake: 0.3701  D(x): 0.9849  D(G(z)): 0.0548  latent_norm : 14.6592  \n",
      "[13/55][800/937]  Loss_D: 0.1261  Loss_G: -0.0670  Loss_R_real: 0.0402  Loss_R_fake: 0.3660  D(x): 0.9592  D(G(z)): 0.0324  latent_norm : 16.1595  \n",
      "Model successfully saved.\n",
      "[14/55][200/937]  Loss_D: 0.0600  Loss_G: -0.0311  Loss_R_real: 0.0336  Loss_R_fake: 0.3358  D(x): 0.9938  D(G(z)): 0.0044  latent_norm : 15.8665  \n",
      "[14/55][400/937]  Loss_D: 0.2363  Loss_G: -0.1507  Loss_R_real: 0.0431  Loss_R_fake: 0.3438  D(x): 0.9760  D(G(z)): 0.0243  latent_norm : 16.7811  \n",
      "[14/55][600/937]  Loss_D: 0.1833  Loss_G: -0.1136  Loss_R_real: 0.0393  Loss_R_fake: 0.3570  D(x): 0.9862  D(G(z)): 0.0280  latent_norm : 15.8030  \n",
      "[14/55][800/937]  Loss_D: 0.1523  Loss_G: -0.0928  Loss_R_real: 0.0374  Loss_R_fake: 0.3499  D(x): 0.9895  D(G(z)): 0.0269  latent_norm : 15.5796  \n",
      "Model successfully saved.\n",
      "[15/55][200/937]  Loss_D: 0.0511  Loss_G: -0.0263  Loss_R_real: 0.0330  Loss_R_fake: 0.3821  D(x): 0.9861  D(G(z)): 0.0296  latent_norm : 16.3561  \n",
      "[15/55][400/937]  Loss_D: 0.0603  Loss_G: -0.0316  Loss_R_real: 0.0342  Loss_R_fake: 0.3763  D(x): 0.9305  D(G(z)): 0.0180  latent_norm : 15.6361  \n",
      "[15/55][600/937]  Loss_D: 0.0903  Loss_G: -0.0333  Loss_R_real: 0.0351  Loss_R_fake: 0.3716  D(x): 1.0000  D(G(z)): 0.0000  latent_norm : 16.6342  \n",
      "[15/55][800/937]  Loss_D: 0.0955  Loss_G: -0.0444  Loss_R_real: 0.0384  Loss_R_fake: 0.3702  D(x): 0.9716  D(G(z)): 0.0242  latent_norm : 16.4451  \n",
      "Model successfully saved.\n",
      "[16/55][200/937]  Loss_D: 0.0352  Loss_G: -0.0182  Loss_R_real: 0.0300  Loss_R_fake: 0.3572  D(x): 0.9847  D(G(z)): 0.0097  latent_norm : 14.9436  \n",
      "[16/55][400/937]  Loss_D: 0.0332  Loss_G: -0.0171  Loss_R_real: 0.0303  Loss_R_fake: 0.3417  D(x): 0.9887  D(G(z)): 0.0044  latent_norm : 15.6346  \n",
      "[16/55][600/937]  Loss_D: 0.0802  Loss_G: -0.0527  Loss_R_real: 0.0390  Loss_R_fake: 0.3613  D(x): 0.9922  D(G(z)): 0.0039  latent_norm : 15.5621  \n",
      "[16/55][800/937]  Loss_D: 0.0711  Loss_G: -0.0454  Loss_R_real: 0.0371  Loss_R_fake: 0.3524  D(x): 0.9926  D(G(z)): 0.0020  latent_norm : 15.6950  \n",
      "Model successfully saved.\n",
      "[17/55][200/937]  Loss_D: 0.0348  Loss_G: -0.0180  Loss_R_real: 0.0297  Loss_R_fake: 0.3733  D(x): 0.9851  D(G(z)): 0.0064  latent_norm : 15.6500  \n",
      "[17/55][400/937]  Loss_D: 0.1541  Loss_G: -0.1050  Loss_R_real: 0.0338  Loss_R_fake: 0.3462  D(x): 0.9982  D(G(z)): 0.0030  latent_norm : 16.2753  \n",
      "[17/55][600/937]  Loss_D: 0.1144  Loss_G: -0.0763  Loss_R_real: 0.0343  Loss_R_fake: 0.3468  D(x): 0.9785  D(G(z)): 0.0153  latent_norm : 15.7999  \n",
      "[17/55][800/937]  Loss_D: 0.0925  Loss_G: -0.0606  Loss_R_real: 0.0327  Loss_R_fake: 0.3495  D(x): 0.9944  D(G(z)): 0.0024  latent_norm : 16.3026  \n",
      "Model successfully saved.\n",
      "[18/55][200/937]  Loss_D: 0.1305  Loss_G: -0.0756  Loss_R_real: 0.0353  Loss_R_fake: 0.3490  D(x): 0.9857  D(G(z)): 0.0000  latent_norm : 13.5281  \n",
      "[18/55][400/937]  Loss_D: 0.0868  Loss_G: -0.0499  Loss_R_real: 0.0379  Loss_R_fake: 0.3488  D(x): 0.9719  D(G(z)): 0.0106  latent_norm : 14.9999  \n",
      "[18/55][600/937]  Loss_D: 0.0710  Loss_G: -0.0398  Loss_R_real: 0.0349  Loss_R_fake: 0.3380  D(x): 0.9936  D(G(z)): 0.0114  latent_norm : 15.5021  \n",
      "[18/55][800/937]  Loss_D: 0.0589  Loss_G: -0.0327  Loss_R_real: 0.0330  Loss_R_fake: 0.3334  D(x): 0.9984  D(G(z)): 0.0082  latent_norm : 15.5551  \n",
      "Model successfully saved.\n",
      "[19/55][200/937]  Loss_D: 0.1065  Loss_G: -0.0550  Loss_R_real: 0.0385  Loss_R_fake: 0.3672  D(x): 0.9998  D(G(z)): 0.0023  latent_norm : 16.0544  \n",
      "[19/55][400/937]  Loss_D: 0.0608  Loss_G: -0.0318  Loss_R_real: 0.0361  Loss_R_fake: 0.3468  D(x): 0.9992  D(G(z)): 0.0108  latent_norm : 15.9846  \n",
      "[19/55][600/937]  Loss_D: 0.0457  Loss_G: -0.0238  Loss_R_real: 0.0326  Loss_R_fake: 0.3308  D(x): 0.9917  D(G(z)): 0.0009  latent_norm : 15.7734  \n",
      "[19/55][800/937]  Loss_D: 0.0395  Loss_G: -0.0205  Loss_R_real: 0.0309  Loss_R_fake: 0.3202  D(x): 0.9914  D(G(z)): 0.0159  latent_norm : 15.3180  \n",
      "Model successfully saved.\n",
      "[20/55][200/937]  Loss_D: 0.0073  Loss_G: -0.0044  Loss_R_real: 0.0325  Loss_R_fake: 0.3018  D(x): 0.9937  D(G(z)): 0.0018  latent_norm : 15.1607  \n",
      "[20/55][400/937]  Loss_D: 0.0110  Loss_G: -0.0062  Loss_R_real: 0.0294  Loss_R_fake: 0.2864  D(x): 0.9946  D(G(z)): 0.0004  latent_norm : 14.5854  \n",
      "[20/55][600/937]  Loss_D: 0.0105  Loss_G: -0.0058  Loss_R_real: 0.0283  Loss_R_fake: 0.2957  D(x): 0.9949  D(G(z)): 0.0067  latent_norm : 16.4820  \n",
      "[20/55][800/937]  Loss_D: 0.0540  Loss_G: -0.0157  Loss_R_real: 0.0318  Loss_R_fake: 0.3086  D(x): 0.9938  D(G(z)): 0.0083  latent_norm : 15.7166  \n",
      "Model successfully saved.\n",
      "[21/55][200/937]  Loss_D: 0.0192  Loss_G: -0.0099  Loss_R_real: 0.0250  Loss_R_fake: 0.3129  D(x): 0.9977  D(G(z)): 0.0144  latent_norm : 14.8698  \n",
      "[21/55][400/937]  Loss_D: 0.0535  Loss_G: -0.0270  Loss_R_real: 0.0292  Loss_R_fake: 0.3119  D(x): 0.9932  D(G(z)): 0.0016  latent_norm : 15.0864  \n",
      "[21/55][600/937]  Loss_D: 0.0410  Loss_G: -0.0209  Loss_R_real: 0.0282  Loss_R_fake: 0.3119  D(x): 0.9786  D(G(z)): 0.0122  latent_norm : 16.5421  \n",
      "[21/55][800/937]  Loss_D: 0.0349  Loss_G: -0.0178  Loss_R_real: 0.0275  Loss_R_fake: 0.3231  D(x): 0.9969  D(G(z)): 0.0007  latent_norm : 15.7554  \n",
      "Model successfully saved.\n",
      "[22/55][200/937]  Loss_D: 0.0223  Loss_G: -0.0126  Loss_R_real: 0.0290  Loss_R_fake: 0.3162  D(x): 0.9669  D(G(z)): 0.0012  latent_norm : 16.0058  \n",
      "[22/55][400/937]  Loss_D: 0.0167  Loss_G: -0.0093  Loss_R_real: 0.0268  Loss_R_fake: 0.3164  D(x): 0.9977  D(G(z)): 0.0051  latent_norm : 15.7339  \n",
      "[22/55][600/937]  Loss_D: 0.0176  Loss_G: -0.0096  Loss_R_real: 0.0268  Loss_R_fake: 0.3213  D(x): 0.9978  D(G(z)): 0.0006  latent_norm : 15.8267  \n",
      "[22/55][800/937]  Loss_D: 0.0346  Loss_G: -0.0203  Loss_R_real: 0.0266  Loss_R_fake: 0.3214  D(x): 0.3760  D(G(z)): 0.5124  latent_norm : 14.1035  \n",
      "Model successfully saved.\n",
      "[23/55][200/937]  Loss_D: 0.0148  Loss_G: -0.0073  Loss_R_real: 0.0262  Loss_R_fake: 0.3154  D(x): 0.9962  D(G(z)): 0.0020  latent_norm : 15.7346  \n",
      "[23/55][400/937]  Loss_D: 0.0132  Loss_G: -0.0066  Loss_R_real: 0.0252  Loss_R_fake: 0.3097  D(x): 0.9925  D(G(z)): 0.0102  latent_norm : 16.1465  \n",
      "[23/55][600/937]  Loss_D: 0.0139  Loss_G: -0.0070  Loss_R_real: 0.0250  Loss_R_fake: 0.3115  D(x): 0.9933  D(G(z)): 0.0057  latent_norm : 15.1168  \n",
      "[23/55][800/937]  Loss_D: 0.0452  Loss_G: -0.0169  Loss_R_real: 0.0284  Loss_R_fake: 0.3197  D(x): 0.9963  D(G(z)): 0.0047  latent_norm : 15.3604  \n",
      "Model successfully saved.\n",
      "[24/55][200/937]  Loss_D: 0.0129  Loss_G: -0.0072  Loss_R_real: 0.0238  Loss_R_fake: 0.2819  D(x): 0.9941  D(G(z)): 0.0014  latent_norm : 16.3624  \n",
      "[24/55][400/937]  Loss_D: 0.0961  Loss_G: -0.0532  Loss_R_real: 0.0294  Loss_R_fake: 0.3201  D(x): 0.9821  D(G(z)): 0.0454  latent_norm : 15.0677  \n",
      "[24/55][600/937]  Loss_D: 0.0734  Loss_G: -0.0404  Loss_R_real: 0.0287  Loss_R_fake: 0.3223  D(x): 0.9911  D(G(z)): 0.0057  latent_norm : 15.4711  \n",
      "[24/55][800/937]  Loss_D: 0.0595  Loss_G: -0.0326  Loss_R_real: 0.0275  Loss_R_fake: 0.3311  D(x): 0.9985  D(G(z)): 0.0049  latent_norm : 15.1078  \n",
      "Model successfully saved.\n",
      "[25/55][200/937]  Loss_D: 0.0190  Loss_G: -0.0101  Loss_R_real: 0.0243  Loss_R_fake: 0.2950  D(x): 0.9946  D(G(z)): 0.0018  latent_norm : 16.3364  \n",
      "[25/55][400/937]  Loss_D: 0.0158  Loss_G: -0.0083  Loss_R_real: 0.0238  Loss_R_fake: 0.3115  D(x): 0.9892  D(G(z)): 0.0018  latent_norm : 15.1915  \n",
      "[25/55][600/937]  Loss_D: 0.0287  Loss_G: -0.0179  Loss_R_real: 0.0268  Loss_R_fake: 0.3187  D(x): 0.9955  D(G(z)): 0.0040  latent_norm : 14.8743  \n",
      "[25/55][800/937]  Loss_D: 0.0243  Loss_G: -0.0149  Loss_R_real: 0.0258  Loss_R_fake: 0.3022  D(x): 0.9992  D(G(z)): 0.0002  latent_norm : 15.2320  \n",
      "Model successfully saved.\n",
      "[26/55][200/937]  Loss_D: 0.0334  Loss_G: -0.0188  Loss_R_real: 0.0352  Loss_R_fake: 0.3122  D(x): 0.9950  D(G(z)): 0.0053  latent_norm : 15.5920  \n",
      "[26/55][400/937]  Loss_D: 0.0251  Loss_G: -0.0138  Loss_R_real: 0.0291  Loss_R_fake: 0.3200  D(x): 0.9939  D(G(z)): 0.0025  latent_norm : 15.7161  \n",
      "[26/55][600/937]  Loss_D: 0.0213  Loss_G: -0.0116  Loss_R_real: 0.0268  Loss_R_fake: 0.3151  D(x): 0.9991  D(G(z)): 0.0033  latent_norm : 15.5729  \n",
      "[26/55][800/937]  Loss_D: 0.0194  Loss_G: -0.0105  Loss_R_real: 0.0258  Loss_R_fake: 0.3093  D(x): 0.9877  D(G(z)): 0.0275  latent_norm : 15.0939  \n",
      "Model successfully saved.\n",
      "[27/55][200/937]  Loss_D: 0.1030  Loss_G: -0.0607  Loss_R_real: 0.0345  Loss_R_fake: 0.3305  D(x): 0.9985  D(G(z)): 0.0086  latent_norm : 15.4809  \n",
      "[27/55][400/937]  Loss_D: 0.0579  Loss_G: -0.0338  Loss_R_real: 0.0281  Loss_R_fake: 0.3056  D(x): 0.9697  D(G(z)): 0.0008  latent_norm : 17.2182  \n",
      "[27/55][600/937]  Loss_D: 0.0415  Loss_G: -0.0241  Loss_R_real: 0.0260  Loss_R_fake: 0.3028  D(x): 0.9980  D(G(z)): 0.0019  latent_norm : 16.2866  \n",
      "[27/55][800/937]  Loss_D: 0.0345  Loss_G: -0.0198  Loss_R_real: 0.0251  Loss_R_fake: 0.3047  D(x): 0.9985  D(G(z)): 0.0001  latent_norm : 16.4841  \n",
      "Model successfully saved.\n",
      "[28/55][200/937]  Loss_D: 0.0100  Loss_G: -0.0052  Loss_R_real: 0.0213  Loss_R_fake: 0.3245  D(x): 0.9975  D(G(z)): 0.0026  latent_norm : 16.2699  \n",
      "[28/55][400/937]  Loss_D: 0.0106  Loss_G: -0.0055  Loss_R_real: 0.0215  Loss_R_fake: 0.3071  D(x): 0.9939  D(G(z)): 0.0034  latent_norm : 15.3733  \n",
      "[28/55][600/937]  Loss_D: 0.0109  Loss_G: -0.0056  Loss_R_real: 0.0217  Loss_R_fake: 0.3095  D(x): 0.9989  D(G(z)): 0.0046  latent_norm : 15.1532  \n",
      "[28/55][800/937]  Loss_D: 0.0305  Loss_G: -0.0149  Loss_R_real: 0.0248  Loss_R_fake: 0.3068  D(x): 0.9482  D(G(z)): 0.0699  latent_norm : 16.0111  \n",
      "Model successfully saved.\n",
      "[29/55][200/937]  Loss_D: 0.0166  Loss_G: -0.0080  Loss_R_real: 0.0218  Loss_R_fake: 0.2705  D(x): 0.9987  D(G(z)): 0.0056  latent_norm : 16.0254  \n",
      "[29/55][400/937]  Loss_D: 0.0121  Loss_G: -0.0061  Loss_R_real: 0.0215  Loss_R_fake: 0.2977  D(x): 0.9972  D(G(z)): 0.0004  latent_norm : 15.3866  \n",
      "[29/55][600/937]  Loss_D: 0.0115  Loss_G: -0.0058  Loss_R_real: 0.0214  Loss_R_fake: 0.2972  D(x): 0.9977  D(G(z)): 0.0096  latent_norm : 15.7055  \n",
      "[29/55][800/937]  Loss_D: 0.0114  Loss_G: -0.0057  Loss_R_real: 0.0215  Loss_R_fake: 0.2930  D(x): 0.9932  D(G(z)): 0.0013  latent_norm : 15.9164  \n",
      "Model successfully saved.\n",
      "[30/55][200/937]  Loss_D: 0.2305  Loss_G: -0.1663  Loss_R_real: 0.0421  Loss_R_fake: 0.3403  D(x): 0.9826  D(G(z)): 0.0050  latent_norm : 15.1162  \n",
      "[30/55][400/937]  Loss_D: 0.1205  Loss_G: -0.0860  Loss_R_real: 0.0315  Loss_R_fake: 0.3135  D(x): 0.9954  D(G(z)): 0.0018  latent_norm : 16.2583  \n",
      "[30/55][600/937]  Loss_D: 0.0832  Loss_G: -0.0588  Loss_R_real: 0.0278  Loss_R_fake: 0.3062  D(x): 0.9988  D(G(z)): 0.0003  latent_norm : 15.8238  \n",
      "[30/55][800/937]  Loss_D: 0.0638  Loss_G: -0.0448  Loss_R_real: 0.0260  Loss_R_fake: 0.3020  D(x): 0.9990  D(G(z)): 0.0017  latent_norm : 16.3992  \n",
      "Model successfully saved.\n",
      "[31/55][200/937]  Loss_D: 0.0098  Loss_G: -0.0054  Loss_R_real: 0.0256  Loss_R_fake: 0.3071  D(x): 0.9882  D(G(z)): 0.0006  latent_norm : 15.3125  \n",
      "[31/55][400/937]  Loss_D: 0.0081  Loss_G: -0.0044  Loss_R_real: 0.0236  Loss_R_fake: 0.2876  D(x): 0.9987  D(G(z)): 0.0022  latent_norm : 15.1376  \n",
      "[31/55][600/937]  Loss_D: 0.0080  Loss_G: -0.0042  Loss_R_real: 0.0225  Loss_R_fake: 0.2832  D(x): 0.9985  D(G(z)): 0.0013  latent_norm : 16.8693  \n",
      "[31/55][800/937]  Loss_D: 0.0107  Loss_G: -0.0055  Loss_R_real: 0.0228  Loss_R_fake: 0.2892  D(x): 0.9971  D(G(z)): 0.0025  latent_norm : 16.2631  \n",
      "Model successfully saved.\n",
      "[32/55][200/937]  Loss_D: 0.0077  Loss_G: -0.0041  Loss_R_real: 0.0207  Loss_R_fake: 0.3080  D(x): 0.9961  D(G(z)): 0.0015  latent_norm : 15.1127  \n",
      "[32/55][400/937]  Loss_D: 0.0655  Loss_G: -0.0199  Loss_R_real: 0.0287  Loss_R_fake: 0.3291  D(x): 0.9908  D(G(z)): 0.0132  latent_norm : 15.4099  \n",
      "[32/55][600/937]  Loss_D: 0.0509  Loss_G: -0.0171  Loss_R_real: 0.0266  Loss_R_fake: 0.3239  D(x): 0.9812  D(G(z)): 0.0088  latent_norm : 15.6532  \n",
      "[32/55][800/937]  Loss_D: 0.0406  Loss_G: -0.0140  Loss_R_real: 0.0251  Loss_R_fake: 0.3221  D(x): 0.9982  D(G(z)): 0.0060  latent_norm : 15.8862  \n",
      "Model successfully saved.\n",
      "[33/55][200/937]  Loss_D: 0.0075  Loss_G: -0.0039  Loss_R_real: 0.0208  Loss_R_fake: 0.2679  D(x): 0.9995  D(G(z)): 0.0005  latent_norm : 16.6090  \n",
      "[33/55][400/937]  Loss_D: 0.0076  Loss_G: -0.0040  Loss_R_real: 0.0213  Loss_R_fake: 0.2667  D(x): 0.9978  D(G(z)): 0.0015  latent_norm : 15.2536  \n",
      "[33/55][600/937]  Loss_D: 0.0629  Loss_G: -0.0392  Loss_R_real: 0.0252  Loss_R_fake: 0.2844  D(x): 0.9992  D(G(z)): 0.0002  latent_norm : 15.2366  \n",
      "[33/55][800/937]  Loss_D: 0.0493  Loss_G: -0.0306  Loss_R_real: 0.0252  Loss_R_fake: 0.2872  D(x): 0.9975  D(G(z)): 0.0041  latent_norm : 15.6531  \n",
      "Model successfully saved.\n",
      "[34/55][200/937]  Loss_D: 0.0074  Loss_G: -0.0041  Loss_R_real: 0.0206  Loss_R_fake: 0.2883  D(x): 0.9991  D(G(z)): 0.0015  latent_norm : 15.1031  \n",
      "[34/55][400/937]  Loss_D: 0.0093  Loss_G: -0.0048  Loss_R_real: 0.0206  Loss_R_fake: 0.2827  D(x): 0.9998  D(G(z)): 0.0008  latent_norm : 14.6066  \n",
      "[34/55][600/937]  Loss_D: 0.0075  Loss_G: -0.0039  Loss_R_real: 0.0204  Loss_R_fake: 0.2860  D(x): 0.9993  D(G(z)): 0.0063  latent_norm : 14.1364  \n",
      "[34/55][800/937]  Loss_D: 0.0350  Loss_G: -0.0112  Loss_R_real: 0.0242  Loss_R_fake: 0.2939  D(x): 0.9987  D(G(z)): 0.0037  latent_norm : 15.5021  \n",
      "Model successfully saved.\n",
      "[35/55][200/937]  Loss_D: 0.0046  Loss_G: -0.0026  Loss_R_real: 0.0205  Loss_R_fake: 0.3009  D(x): 0.9950  D(G(z)): 0.0003  latent_norm : 15.3113  \n",
      "[35/55][400/937]  Loss_D: 0.0076  Loss_G: -0.0040  Loss_R_real: 0.0202  Loss_R_fake: 0.3019  D(x): 0.9776  D(G(z)): 0.0023  latent_norm : 15.9973  \n",
      "[35/55][600/937]  Loss_D: 0.0092  Loss_G: -0.0047  Loss_R_real: 0.0203  Loss_R_fake: 0.3102  D(x): 0.9977  D(G(z)): 0.0002  latent_norm : 16.6925  \n",
      "[35/55][800/937]  Loss_D: 0.0097  Loss_G: -0.0050  Loss_R_real: 0.0205  Loss_R_fake: 0.3084  D(x): 0.9979  D(G(z)): 0.0005  latent_norm : 14.7509  \n",
      "Model successfully saved.\n",
      "[36/55][200/937]  Loss_D: 0.0072  Loss_G: -0.0037  Loss_R_real: 0.0199  Loss_R_fake: 0.2690  D(x): 0.9993  D(G(z)): 0.0023  latent_norm : 15.6544  \n",
      "[36/55][400/937]  Loss_D: 0.0092  Loss_G: -0.0047  Loss_R_real: 0.0198  Loss_R_fake: 0.2823  D(x): 0.9979  D(G(z)): 0.0063  latent_norm : 14.5107  \n",
      "[36/55][600/937]  Loss_D: 0.0087  Loss_G: -0.0045  Loss_R_real: 0.0197  Loss_R_fake: 0.2814  D(x): 0.9940  D(G(z)): 0.0008  latent_norm : 16.0518  \n",
      "[36/55][800/937]  Loss_D: 0.0080  Loss_G: -0.0041  Loss_R_real: 0.0196  Loss_R_fake: 0.2842  D(x): 0.9900  D(G(z)): 0.0058  latent_norm : 15.8630  \n",
      "Model successfully saved.\n",
      "[37/55][200/937]  Loss_D: 0.0086  Loss_G: -0.0043  Loss_R_real: 0.0208  Loss_R_fake: 0.2755  D(x): 0.9989  D(G(z)): 0.0005  latent_norm : 16.1562  \n",
      "[37/55][400/937]  Loss_D: 0.0088  Loss_G: -0.0044  Loss_R_real: 0.0199  Loss_R_fake: 0.2865  D(x): 0.9806  D(G(z)): 0.0049  latent_norm : 16.4620  \n",
      "[37/55][600/937]  Loss_D: 0.0083  Loss_G: -0.0042  Loss_R_real: 0.0195  Loss_R_fake: 0.2800  D(x): 0.9984  D(G(z)): 0.0018  latent_norm : 15.9024  \n",
      "[37/55][800/937]  Loss_D: 0.0076  Loss_G: -0.0038  Loss_R_real: 0.0194  Loss_R_fake: 0.2784  D(x): 0.9990  D(G(z)): 0.0009  latent_norm : 15.7701  \n",
      "Model successfully saved.\n",
      "[38/55][200/937]  Loss_D: 0.1299  Loss_G: -0.0784  Loss_R_real: 0.0335  Loss_R_fake: 0.3193  D(x): 0.9966  D(G(z)): 0.0002  latent_norm : 16.0733  \n",
      "[38/55][400/937]  Loss_D: 0.0687  Loss_G: -0.0412  Loss_R_real: 0.0268  Loss_R_fake: 0.3075  D(x): 0.9989  D(G(z)): 0.0004  latent_norm : 15.3535  \n",
      "[38/55][600/937]  Loss_D: 0.0485  Loss_G: -0.0288  Loss_R_real: 0.0242  Loss_R_fake: 0.3046  D(x): 0.9994  D(G(z)): 0.0032  latent_norm : 15.6333  \n",
      "[38/55][800/937]  Loss_D: 0.0380  Loss_G: -0.0224  Loss_R_real: 0.0227  Loss_R_fake: 0.2994  D(x): 0.9977  D(G(z)): 0.0033  latent_norm : 15.9627  \n",
      "Model successfully saved.\n",
      "[39/55][200/937]  Loss_D: 0.0064  Loss_G: -0.0034  Loss_R_real: 0.0208  Loss_R_fake: 0.3023  D(x): 0.9994  D(G(z)): 0.0046  latent_norm : 15.2198  \n",
      "[39/55][400/937]  Loss_D: 0.0066  Loss_G: -0.0036  Loss_R_real: 0.0196  Loss_R_fake: 0.2836  D(x): 0.9997  D(G(z)): 0.0007  latent_norm : 14.8090  \n",
      "[39/55][600/937]  Loss_D: 0.0171  Loss_G: -0.0076  Loss_R_real: 0.0203  Loss_R_fake: 0.2745  D(x): 0.9980  D(G(z)): 0.0020  latent_norm : 14.8754  \n",
      "[39/55][800/937]  Loss_D: 0.0141  Loss_G: -0.0064  Loss_R_real: 0.0201  Loss_R_fake: 0.2830  D(x): 0.9990  D(G(z)): 0.0001  latent_norm : 15.7442  \n",
      "Model successfully saved.\n",
      "[40/55][200/937]  Loss_D: 0.0073  Loss_G: -0.0040  Loss_R_real: 0.0191  Loss_R_fake: 0.3036  D(x): 0.9997  D(G(z)): 0.0001  latent_norm : 16.7908  \n",
      "[40/55][400/937]  Loss_D: 0.0061  Loss_G: -0.0033  Loss_R_real: 0.0191  Loss_R_fake: 0.2873  D(x): 0.9990  D(G(z)): 0.0109  latent_norm : 16.0931  \n",
      "[40/55][600/937]  Loss_D: 0.0339  Loss_G: -0.0072  Loss_R_real: 0.0206  Loss_R_fake: 0.2857  D(x): 0.9946  D(G(z)): 0.0057  latent_norm : 15.7422  \n",
      "[40/55][800/937]  Loss_D: 0.0300  Loss_G: -0.0077  Loss_R_real: 0.0218  Loss_R_fake: 0.2794  D(x): 0.9996  D(G(z)): 0.0175  latent_norm : 15.3166  \n",
      "Model successfully saved.\n",
      "[41/55][200/937]  Loss_D: 0.0083  Loss_G: -0.0043  Loss_R_real: 0.0188  Loss_R_fake: 0.2827  D(x): 0.9971  D(G(z)): 0.0006  latent_norm : 16.3227  \n",
      "[41/55][400/937]  Loss_D: 0.0609  Loss_G: -0.0365  Loss_R_real: 0.0265  Loss_R_fake: 0.2776  D(x): 0.9978  D(G(z)): 0.0011  latent_norm : 15.5544  \n",
      "[41/55][600/937]  Loss_D: 0.0430  Loss_G: -0.0256  Loss_R_real: 0.0241  Loss_R_fake: 0.2801  D(x): 0.9993  D(G(z)): 0.0028  latent_norm : 15.5779  \n",
      "[41/55][800/937]  Loss_D: 0.0339  Loss_G: -0.0201  Loss_R_real: 0.0227  Loss_R_fake: 0.2828  D(x): 0.9994  D(G(z)): 0.0023  latent_norm : 15.6965  \n",
      "Model successfully saved.\n",
      "[42/55][200/937]  Loss_D: 0.0042  Loss_G: -0.0024  Loss_R_real: 0.0190  Loss_R_fake: 0.2857  D(x): 0.9996  D(G(z)): 0.0002  latent_norm : 15.7624  \n",
      "[42/55][400/937]  Loss_D: 0.0037  Loss_G: -0.0021  Loss_R_real: 0.0181  Loss_R_fake: 0.2804  D(x): 0.9914  D(G(z)): 0.0026  latent_norm : 14.8565  \n",
      "[42/55][600/937]  Loss_D: 0.0449  Loss_G: -0.0229  Loss_R_real: 0.0239  Loss_R_fake: 0.2848  D(x): 0.9924  D(G(z)): 0.0006  latent_norm : 15.8733  \n",
      "[42/55][800/937]  Loss_D: 0.0359  Loss_G: -0.0183  Loss_R_real: 0.0226  Loss_R_fake: 0.2718  D(x): 0.9984  D(G(z)): 0.0019  latent_norm : 14.7743  \n",
      "Model successfully saved.\n",
      "[43/55][200/937]  Loss_D: 0.0059  Loss_G: -0.0030  Loss_R_real: 0.0174  Loss_R_fake: 0.2940  D(x): 0.9974  D(G(z)): 0.0002  latent_norm : 16.0707  \n",
      "[43/55][400/937]  Loss_D: 0.0079  Loss_G: -0.0040  Loss_R_real: 0.0178  Loss_R_fake: 0.2852  D(x): 0.9996  D(G(z)): 0.0003  latent_norm : 16.6371  \n",
      "[43/55][600/937]  Loss_D: 0.0403  Loss_G: -0.0202  Loss_R_real: 0.0212  Loss_R_fake: 0.3000  D(x): 0.9972  D(G(z)): 0.0043  latent_norm : 16.0697  \n",
      "[43/55][800/937]  Loss_D: 0.0323  Loss_G: -0.0162  Loss_R_real: 0.0207  Loss_R_fake: 0.2936  D(x): 0.9974  D(G(z)): 0.0002  latent_norm : 16.1679  \n",
      "Model successfully saved.\n",
      "[44/55][200/937]  Loss_D: 0.0049  Loss_G: -0.0025  Loss_R_real: 0.0176  Loss_R_fake: 0.2648  D(x): 0.9984  D(G(z)): 0.0004  latent_norm : 16.1848  \n",
      "[44/55][400/937]  Loss_D: 0.0154  Loss_G: -0.0082  Loss_R_real: 0.0223  Loss_R_fake: 0.2803  D(x): 0.9998  D(G(z)): 0.0003  latent_norm : 15.3297  \n",
      "[44/55][600/937]  Loss_D: 0.0115  Loss_G: -0.0062  Loss_R_real: 0.0210  Loss_R_fake: 0.2850  D(x): 0.9984  D(G(z)): 0.0001  latent_norm : 15.0217  \n",
      "[44/55][800/937]  Loss_D: 0.0113  Loss_G: -0.0058  Loss_R_real: 0.0205  Loss_R_fake: 0.2824  D(x): 0.9967  D(G(z)): 0.0005  latent_norm : 15.4528  \n",
      "Model successfully saved.\n",
      "[45/55][200/937]  Loss_D: 0.0859  Loss_G: -0.0395  Loss_R_real: 0.0259  Loss_R_fake: 0.2905  D(x): 0.9947  D(G(z)): 0.0016  latent_norm : 15.4848  \n",
      "[45/55][400/937]  Loss_D: 0.0460  Loss_G: -0.0214  Loss_R_real: 0.0220  Loss_R_fake: 0.2916  D(x): 0.9889  D(G(z)): 0.0032  latent_norm : 15.8804  \n",
      "[45/55][600/937]  Loss_D: 0.0337  Loss_G: -0.0158  Loss_R_real: 0.0206  Loss_R_fake: 0.2750  D(x): 0.9965  D(G(z)): 0.0011  latent_norm : 15.3020  \n",
      "[45/55][800/937]  Loss_D: 0.0285  Loss_G: -0.0133  Loss_R_real: 0.0199  Loss_R_fake: 0.2724  D(x): 0.9990  D(G(z)): 0.0015  latent_norm : 15.9923  \n",
      "Model successfully saved.\n",
      "[46/55][200/937]  Loss_D: 0.0371  Loss_G: -0.0299  Loss_R_real: 0.0177  Loss_R_fake: 0.2605  D(x): 0.7949  D(G(z)): 0.6516  latent_norm : 16.3028  \n",
      "[46/55][400/937]  Loss_D: 0.0774  Loss_G: -0.0490  Loss_R_real: 0.0243  Loss_R_fake: 0.2713  D(x): 0.9957  D(G(z)): 0.0090  latent_norm : 14.9482  \n",
      "[46/55][600/937]  Loss_D: 0.0542  Loss_G: -0.0339  Loss_R_real: 0.0224  Loss_R_fake: 0.2655  D(x): 0.9989  D(G(z)): 0.0006  latent_norm : 14.4935  \n",
      "[46/55][800/937]  Loss_D: 0.0418  Loss_G: -0.0260  Loss_R_real: 0.0212  Loss_R_fake: 0.2640  D(x): 0.9982  D(G(z)): 0.0017  latent_norm : 14.2868  \n",
      "Model successfully saved.\n",
      "[47/55][200/937]  Loss_D: 0.0035  Loss_G: -0.0019  Loss_R_real: 0.0170  Loss_R_fake: 0.2562  D(x): 0.9989  D(G(z)): 0.0019  latent_norm : 16.5465  \n",
      "[47/55][400/937]  Loss_D: 0.0290  Loss_G: -0.0145  Loss_R_real: 0.0208  Loss_R_fake: 0.2704  D(x): 0.9995  D(G(z)): 0.0004  latent_norm : 15.0641  \n",
      "[47/55][600/937]  Loss_D: 0.0214  Loss_G: -0.0108  Loss_R_real: 0.0196  Loss_R_fake: 0.2781  D(x): 0.9992  D(G(z)): 0.0134  latent_norm : 15.6098  \n",
      "[47/55][800/937]  Loss_D: 0.0174  Loss_G: -0.0088  Loss_R_real: 0.0191  Loss_R_fake: 0.2843  D(x): 0.9996  D(G(z)): 0.0008  latent_norm : 15.9959  \n",
      "Model successfully saved.\n",
      "[48/55][200/937]  Loss_D: 0.0051  Loss_G: -0.0028  Loss_R_real: 0.0173  Loss_R_fake: 0.2662  D(x): 0.9997  D(G(z)): 0.0001  latent_norm : 15.5331  \n",
      "[48/55][400/937]  Loss_D: 0.0089  Loss_G: -0.0046  Loss_R_real: 0.0192  Loss_R_fake: 0.2688  D(x): 0.9998  D(G(z)): 0.0002  latent_norm : 16.2081  \n",
      "[48/55][600/937]  Loss_D: 0.0070  Loss_G: -0.0036  Loss_R_real: 0.0186  Loss_R_fake: 0.2681  D(x): 0.9987  D(G(z)): 0.0078  latent_norm : 14.9379  \n",
      "[48/55][800/937]  Loss_D: 0.0298  Loss_G: -0.0189  Loss_R_real: 0.0235  Loss_R_fake: 0.2784  D(x): 0.9989  D(G(z)): 0.0131  latent_norm : 14.9976  \n",
      "Model successfully saved.\n",
      "[49/55][200/937]  Loss_D: 0.0042  Loss_G: -0.0020  Loss_R_real: 0.0187  Loss_R_fake: 0.2407  D(x): 0.9934  D(G(z)): 0.0008  latent_norm : 16.2584  \n",
      "[49/55][400/937]  Loss_D: 0.0066  Loss_G: -0.0031  Loss_R_real: 0.0183  Loss_R_fake: 0.2556  D(x): 0.9996  D(G(z)): 0.0009  latent_norm : 16.2120  \n",
      "[49/55][600/937]  Loss_D: 0.0067  Loss_G: -0.0032  Loss_R_real: 0.0180  Loss_R_fake: 0.2612  D(x): 0.9998  D(G(z)): 0.0002  latent_norm : 14.5986  \n",
      "[49/55][800/937]  Loss_D: 0.0079  Loss_G: -0.0037  Loss_R_real: 0.0178  Loss_R_fake: 0.2621  D(x): 0.9998  D(G(z)): 0.0159  latent_norm : 15.6066  \n",
      "Model successfully saved.\n",
      "[50/55][200/937]  Loss_D: 0.0038  Loss_G: -0.0020  Loss_R_real: 0.0168  Loss_R_fake: 0.2848  D(x): 0.9995  D(G(z)): 0.0010  latent_norm : 16.2092  \n",
      "[50/55][400/937]  Loss_D: 0.0274  Loss_G: -0.0087  Loss_R_real: 0.0222  Loss_R_fake: 0.2991  D(x): 0.9997  D(G(z)): 0.0003  latent_norm : 16.1592  \n",
      "[50/55][600/937]  Loss_D: 0.0206  Loss_G: -0.0070  Loss_R_real: 0.0207  Loss_R_fake: 0.2879  D(x): 0.9984  D(G(z)): 0.0060  latent_norm : 14.6931  \n",
      "[50/55][800/937]  Loss_D: 0.0175  Loss_G: -0.0062  Loss_R_real: 0.0202  Loss_R_fake: 0.2895  D(x): 0.9963  D(G(z)): 0.0003  latent_norm : 16.5666  \n",
      "Model successfully saved.\n",
      "[51/55][200/937]  Loss_D: 0.0062  Loss_G: -0.0030  Loss_R_real: 0.0173  Loss_R_fake: 0.2916  D(x): 0.9612  D(G(z)): 0.0223  latent_norm : 15.7250  \n",
      "[51/55][400/937]  Loss_D: 0.0439  Loss_G: -0.0206  Loss_R_real: 0.0227  Loss_R_fake: 0.2965  D(x): 0.9996  D(G(z)): 0.0002  latent_norm : 16.1326  \n",
      "[51/55][600/937]  Loss_D: 0.0305  Loss_G: -0.0144  Loss_R_real: 0.0208  Loss_R_fake: 0.2942  D(x): 0.9983  D(G(z)): 0.0010  latent_norm : 15.1581  \n",
      "[51/55][800/937]  Loss_D: 0.0253  Loss_G: -0.0119  Loss_R_real: 0.0200  Loss_R_fake: 0.2857  D(x): 0.9998  D(G(z)): 0.0060  latent_norm : 15.3173  \n",
      "Model successfully saved.\n",
      "[52/55][200/937]  Loss_D: 0.0559  Loss_G: -0.0248  Loss_R_real: 0.0245  Loss_R_fake: 0.2971  D(x): 0.9990  D(G(z)): 0.0030  latent_norm : 16.5722  \n",
      "[52/55][400/937]  Loss_D: 0.0318  Loss_G: -0.0142  Loss_R_real: 0.0215  Loss_R_fake: 0.2755  D(x): 0.9995  D(G(z)): 0.0002  latent_norm : 15.6167  \n",
      "[52/55][600/937]  Loss_D: 0.0234  Loss_G: -0.0106  Loss_R_real: 0.0201  Loss_R_fake: 0.2645  D(x): 0.9997  D(G(z)): 0.0021  latent_norm : 15.2050  \n",
      "[52/55][800/937]  Loss_D: 0.0180  Loss_G: -0.0082  Loss_R_real: 0.0192  Loss_R_fake: 0.2690  D(x): 0.9996  D(G(z)): 0.0005  latent_norm : 15.4821  \n",
      "Model successfully saved.\n",
      "[53/55][200/937]  Loss_D: 0.0064  Loss_G: -0.0033  Loss_R_real: 0.0176  Loss_R_fake: 0.2634  D(x): 0.9996  D(G(z)): 0.0024  latent_norm : 15.2717  \n",
      "[53/55][400/937]  Loss_D: 0.0090  Loss_G: -0.0047  Loss_R_real: 0.0179  Loss_R_fake: 0.2673  D(x): 0.9997  D(G(z)): 0.0013  latent_norm : 15.1087  \n",
      "[53/55][600/937]  Loss_D: 0.0083  Loss_G: -0.0043  Loss_R_real: 0.0177  Loss_R_fake: 0.2647  D(x): 0.9998  D(G(z)): 0.0085  latent_norm : 15.4811  \n",
      "[53/55][800/937]  Loss_D: 0.0255  Loss_G: -0.0113  Loss_R_real: 0.0206  Loss_R_fake: 0.2697  D(x): 0.9994  D(G(z)): 0.0035  latent_norm : 16.3381  \n",
      "Model successfully saved.\n",
      "[54/55][200/937]  Loss_D: 0.0048  Loss_G: -0.0025  Loss_R_real: 0.0165  Loss_R_fake: 0.2482  D(x): 0.9975  D(G(z)): 0.0010  latent_norm : 16.0996  \n",
      "[54/55][400/937]  Loss_D: 0.0049  Loss_G: -0.0026  Loss_R_real: 0.0166  Loss_R_fake: 0.2576  D(x): 0.9981  D(G(z)): 0.0000  latent_norm : 14.6039  \n",
      "[54/55][600/937]  Loss_D: 0.0048  Loss_G: -0.0025  Loss_R_real: 0.0169  Loss_R_fake: 0.2632  D(x): 0.9995  D(G(z)): 0.0088  latent_norm : 15.0981  \n",
      "[54/55][800/937]  Loss_D: 0.0154  Loss_G: -0.0072  Loss_R_real: 0.0188  Loss_R_fake: 0.2665  D(x): 0.9919  D(G(z)): 0.0023  latent_norm : 15.9584  \n",
      "Model successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# Enable anomaly detection during training (optional)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(len(d_losses), opt.niter):\n",
    "    \n",
    "    # Initialize lists to store losses and other metrics\n",
    "    store_loss_D = []\n",
    "    store_loss_G = []\n",
    "    store_loss_R_real = []\n",
    "    store_loss_R_fake = []\n",
    "    store_norm = []\n",
    "    store_kl = []\n",
    "\n",
    "    # Iterate over the data batches\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # Wake (W)\n",
    "        ###########################\n",
    "\n",
    "        # Discrimination wake\n",
    "        discriminator_optimizer .zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Fetch real images and labels\n",
    "        real_image, label = data\n",
    "        real_image, label = real_image.to(device), label.to(device)\n",
    "\n",
    "        # Pass real images through the discriminator\n",
    "        latent_output, dis_output = discriminator(real_image)\n",
    "\n",
    "        # Add noise to the latent space\n",
    "        latent_output_noise = latent_output + opt.epsilon * torch.randn(batch_size, latent_size, device=device)\n",
    "\n",
    "        # Set the discriminator label for real images\n",
    "        discriminator_label[:] = real_label_value\n",
    "\n",
    "        # Compute the discriminator loss for real images\n",
    "        dis_errD_real = discriminator_criterion(dis_output, discriminator_label)\n",
    "\n",
    "        if opt.R > 0.0:  # if GAN learning occurs\n",
    "            (dis_errD_real).backward(retain_graph=True)\n",
    "\n",
    "        # Compute the KL divergence regularization loss\n",
    "        kl = kl_loss(latent_output)\n",
    "        (kl).backward(retain_graph=True)\n",
    "\n",
    "        # Reconstruct real images from the latent space\n",
    "        reconstructed_image = generator(latent_output_noise, reverse=False)\n",
    "\n",
    "        # Compute the reconstruction loss for real images\n",
    "        rec_real = reconstruction_criterion (reconstructed_image, real_image)\n",
    "\n",
    "        if opt.W > 0.0:\n",
    "            (opt.W * rec_real).backward()\n",
    "\n",
    "        discriminator_optimizer .step()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Compute the mean of the discriminator output (between 0 and 1)\n",
    "        D_x = dis_output.cpu().mean()\n",
    "\n",
    "        # Compute the norm of the latent space representation\n",
    "        latent_norm = torch.mean(torch.norm(latent_output.squeeze(), dim=1)).item()\n",
    "\n",
    "\n",
    "        ###########################\n",
    "        # NREM perturbed dreaming (N)\n",
    "        ##########################\n",
    "        discriminator_optimizer .zero_grad()\n",
    "\n",
    "        # Detach the latent space representation\n",
    "        latent_z = latent_output.detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Generate images from the detached latent space\n",
    "            nrem_image = generator(latent_z)\n",
    "\n",
    "            # Apply occlusion to the generated images\n",
    "            occlusion = Occlude(drop_rate=random.random(), tile_size=random.randint(1, 8))\n",
    "            occluded_nrem_image = occlusion(nrem_image, dim=1)\n",
    "\n",
    "        # Pass occluded NREM images through the discriminator\n",
    "        latent_recons_dream, _ = discriminator(occluded_nrem_image)\n",
    "\n",
    "        # Compute the reconstruction loss for fake images\n",
    "        rec_fake = reconstruction_criterion (latent_recons_dream, latent_output.detach())\n",
    "\n",
    "        if opt.N > 0.0:\n",
    "            (opt.N * rec_fake).backward()\n",
    "\n",
    "        discriminator_optimizer .step()\n",
    "\n",
    "\n",
    "       ###########################\n",
    "        # REM adversarial dreaming (R)\n",
    "        ##########################\n",
    "\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        lmbd = opt.lmbd\n",
    "        noise = torch.randn(batch_size, latent_size, device=device)\n",
    "        if i==0:\n",
    "            latent_z = 0.5*latent_output.detach() + 0.5*noise\n",
    "        else:\n",
    "            latent_z = 0.25*latent_output.detach() + 0.25*old_latent_output + 0.5*noise\n",
    "        \n",
    "        dreamed_image_adv = generator(latent_z, reverse=True) # activate plasticity switch\n",
    "        latent_recons_dream, dis_output = discriminator(dreamed_image_adv)\n",
    "        discriminator_label[:] = fake_label_value # should be classified as fake\n",
    "        dis_errD_fake = discriminator_criterion(dis_output, discriminator_label)\n",
    "        if opt.R > 0.0: # if GAN learning occurs\n",
    "            dis_errD_fake.backward(retain_graph=True)\n",
    "            discriminator_optimizer.step()\n",
    "            generator_optimizer.step()\n",
    "        dis_errG = - dis_errD_fake\n",
    "\n",
    "        D_G_z1 = dis_output.cpu().mean()\n",
    "\n",
    "        old_latent_output = latent_output.detach()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###########################\n",
    "        # Compute average losses\n",
    "        ###########################\n",
    "        store_loss_G.append(dis_errG.item())\n",
    "        store_loss_D.append((dis_errD_fake + dis_errD_real).item())\n",
    "        store_loss_R_real.append(rec_real.item())\n",
    "        store_loss_R_fake.append(rec_fake.item())\n",
    "        store_norm.append(latent_norm)\n",
    "        store_kl.append(kl.item())\n",
    "        \n",
    "\n",
    "\n",
    "        if i % 200 == 0 and i>1:\n",
    "            print('[%d/%d][%d/%d]  Loss_D: %.4f  Loss_G: %.4f  Loss_R_real: %.4f  Loss_R_fake: %.4f  D(x): %.4f  D(G(z)): %.4f  latent_norm : %.4f  '\n",
    "                % (epoch, opt.niter, i, len(dataloader),\n",
    "                    np.mean(store_loss_D), np.mean(store_loss_G), np.mean(store_loss_R_real), np.mean(store_loss_R_fake), D_x, D_G_z1, np.mean(latent_norm) ))\n",
    "            compare_img_rec = torch.zeros(batch_size * 2, real_image.size(1), real_image.size(2), real_image.size(3))\n",
    "            with torch.no_grad():\n",
    "                reconstructed_image = generator(latent_output)\n",
    "            compare_img_rec[::2] = real_image\n",
    "            compare_img_rec[1::2] = reconstructed_image\n",
    "            vutils.save_image(unorm(compare_img_rec[:128]), '%s/recon_%03d.png' % (dir_files, epoch), nrow=8)\n",
    "            fake = unorm(dreamed_image_adv)\n",
    "            vutils.save_image(fake[:64].data, '%s/fake_%03d.png' % (dir_files, epoch), nrow=8)\n",
    "            \n",
    "\n",
    "    d_losses.append(np.mean(store_loss_D))\n",
    "    g_losses.append(np.mean(store_loss_G))\n",
    "    r_losses_real.append(np.mean(store_loss_R_real))\n",
    "    r_losses_fake.append(np.mean(store_loss_R_fake))\n",
    "    kl_losses.append(np.mean(store_kl))\n",
    "    save_fig_losses(epoch, d_losses, g_losses, r_losses_real, r_losses_fake, kl_losses, None, None,  dir_files)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save({\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'g_optim': generator_optimizer.state_dict(),\n",
    "        'd_optim': discriminator_optimizer.state_dict(),\n",
    "        'd_losses': d_losses,\n",
    "        'g_losses': g_losses,\n",
    "        'r_losses_real': r_losses_real,\n",
    "        'r_losses_fake': r_losses_fake,\n",
    "        'kl_losses': kl_losses,\n",
    "    }, dir_checkpoint+'/trained.pth')\n",
    "    \n",
    "    # save network after 1 learning epoch\n",
    "    if epoch ==1:\n",
    "            torch.save({\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        }, dir_checkpoint+'/trained2.pth')\n",
    "\n",
    "    print(f'Model successfully saved.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
